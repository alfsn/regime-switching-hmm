{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Startup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_datareader as web\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "yf.pdr_override()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroute=os.path.join(\"..\",  \"data\")\n",
    "resultsroute=os.path.join(\"..\",  \"results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickerlist=[\"^MERV\", \n",
    "            \"GGAL\", \"GGAL.BA\", \n",
    "            \"YPF\", \"YPFD.BA\",\n",
    "            \"EDN\", \"EDN.BA\",\n",
    "            \"BMA\", \"BMA.BA\"] \n",
    "# sumar tamb BBAR/BBAR? TEO/TECO2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "factordict={\"GGAL\": 10, \"YPF\":1, \"EDN\":20, \"BMA\":10, \"BBAR\":3, \"TEO\":5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks=tickerlist.copy()\n",
    "stocks.remove(\"^MERV\")\n",
    "stocklist=[]\n",
    "\n",
    "for i in range(0, len(stocks), 2):\n",
    "    stocklist.append((stocks[i], stocks[i+1]))\n",
    "del stocks\n",
    "stocklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohlclist=[\"Open\", \"High\", \"Low\", \"Close\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "objectlist=[]\n",
    "\n",
    "for ticker in tickerlist:\n",
    "    objectlist.append(yf.Ticker(ticker))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get historical market data\n",
    "data={}\n",
    "start='2013-01-01'\n",
    "end=\"2023-06-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=f'dataset_{start}_{end}.pickle'\n",
    "filename=os.path.join(dataroute, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(filename):\n",
    "    for ticker in objectlist:\n",
    "        # descargo data en un diccionario[ticker]\n",
    "        data[ticker.ticker] = ticker.history(start=start, end=end)\n",
    "        # guardo en un pickle\n",
    "    with open(filename, 'wb') as handle:\n",
    "        pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "else:\n",
    "    with open(filename, 'rb') as handle:\n",
    "        data=pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data quality deletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_quality_dates=[\"2022-07-14\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ticker in tickerlist:\n",
    "    data[ticker]=data[ticker].loc[~data[ticker].index.isin(pd.to_datetime(data_quality_dates))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implicit USD calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _reindex_refill_dfs(df1, df2):\n",
    "    \"\"\"\n",
    "    The function returns two dataframes with an index as the union of the two.\n",
    "    The dataframes are then forward filled.\n",
    "    \"\"\"\n",
    "    index3=df1.index.union(df2.index)\n",
    "    # reindex both con index3\n",
    "    df3=df1.reindex(index3)\n",
    "    df4=df2.reindex(index3)\n",
    "    # fillna con previous value\n",
    "    df3.fillna(method=\"ffill\")\n",
    "    df4.fillna(method=\"ffill\")\n",
    "    return df3, df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_usd(usd_df, ars_df, conversion_factor):\n",
    "    \"\"\"\n",
    "    The function returns a dataframe with an index the size of the union between the two.\n",
    "    Missing values in dates (stemming from, for example, holidays in one country) are\n",
    "    forward filled to create the last  \n",
    "    \"\"\"\n",
    "    usd_df_r, ars_df_r = _reindex_refill_dfs(usd_df, ars_df)\n",
    "    implicit_usd = ars_df_r.divide(usd_df_r)*conversion_factor\n",
    "    return implicit_usd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "usdlist=[]\n",
    "for stocktuplo in stocklist:\n",
    "    us, ba = stocktuplo\n",
    "    usdlist.append(f\"USD_{us}\")\n",
    "    data[f\"USD_{us}\"]=calculate_usd(data[us][ohlclist], data[ba][ohlclist], factordict[us])\n",
    "    data[f\"USD_{us}\"][\"Average\"]=data[f\"USD_{us}\"].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"USD\"]=pd.DataFrame(columns=ohlclist)\n",
    "\n",
    "for i in ohlclist:\n",
    "    df=pd.concat([data[col][i] for col in usdlist], axis=1)\n",
    "    data[\"USD\"][i]=df.mean(axis=1)\n",
    "    \n",
    "data[\"USD\"][\"Average\"]=data[\"USD\"].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in data.keys():\n",
    "    data[key].fillna(method=\"ffill\", inplace=True)\n",
    "    # revisar esto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"USD\"][[*ohlclist, \"Average\"]].plot(figsize=(10,10), logy=True, grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USD Denominated Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"USD_^MERV\"]=pd.DataFrame(columns=ohlclist)\n",
    "\n",
    "for col in ohlclist:\n",
    "    data[\"USD_^MERV\"][col] = data[\"^MERV\"][col]/data[\"USD\"][\"Average\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"USD_^MERV\"].fillna(method=\"ffill\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intraday Volatility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a usar para medir intraday volatility el estimador de Garman and Klass (1980):\n",
    "\n",
    "$$V_{ohlc}=0.5*[log(H)-log(L)]^2+(2*log(2)-1)*[log(C)-log(O)]^2$$ \n",
    "Donde H es el precio mas alto del día, L el bajo, C el cierre y O su apertura\n",
    "\n",
    "Garman, M. B. and M. J. Klass (1980). On the estimation of security price volatilities from historical data. Journal of Business 53, 67–78."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gk_vol(o, h, l, c):\n",
    "    \"Returns Garman Klass (1980) intraday volatility estimator\"\n",
    "    return 0.5*(np.log(h)-np.log(l))**2+(2*np.log(2)-1)*(np.log(c)-np.log(o))**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Returns Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ticker in data.keys():\n",
    "    view=data[ticker]\n",
    "    view[\"rets\"] = view[\"Close\"]/view[\"Close\"].shift()-1\n",
    "    view[\"log_rets\"] = np.log(view[\"Close\"]/view[\"Close\"].shift())\n",
    "    view[\"norm_range\"] = (view[\"High\"]-view[\"High\"])/view[\"Open\"]\n",
    "    # chequear si esto tiene asidero\n",
    "    # alternativa (view[\"High\"]-view[\"High\"])/view[\"Close\"]\n",
    "    view[\"gk_vol\"] = gk_vol(o=view[\"Open\"], h=view[\"High\"], l=view[\"Low\"], c=view[\"Close\"])\n",
    "    # delete first observation to eliminate nans\n",
    "    data[ticker]=data[ticker][1:].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "processedname=\"processed_\"+name\n",
    "with open(os.path.join(dataroute, processedname), 'wb') as handle:\n",
    "    pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
