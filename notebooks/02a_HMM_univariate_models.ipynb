{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Startup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from hmmlearn import hmm\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.captureWarnings(True)\n",
    "hmm.logging.disable(level=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "np.random.seed(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.params import get_params\n",
    "from scripts.aux_functions import generate_columns, save_as_pickle, get_all_results_matching, clean_modelname\n",
    "\n",
    "params = get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroute = params[\"dataroute\"]\n",
    "resultsroute = params[\"resultsroute\"]\n",
    "dumproute = params[\"dumproute\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = f'finaldf_train_{params[\"tablename\"]}.pickle'\n",
    "filename = os.path.join(dataroute, name)\n",
    "with open(filename, \"rb\") as handle:\n",
    "    df = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HMM Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_states = range(1, 11)\n",
    "emptydf = pd.DataFrame(columns=[\"AIC\", \"BIC\"], index=range_states)\n",
    "emptydf.fillna(np.inf, inplace=True)\n",
    "results_dict_df = {stock: emptydf for stock in params[\"assetlist\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = {\n",
    "    \"covariance_type\": \"diag\",\n",
    "    \"n_iter\": 500,\n",
    "    \"random_state\": random_state,\n",
    "    # no voy a usar startprob_prior por devlog 20-06-23\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_hmm_model(\n",
    "    df: pd.DataFrame,\n",
    "    tickerlist: list,\n",
    "    range_states,\n",
    "    param_dict: dict,\n",
    "    contains_vol: bool,\n",
    "    contains_USD: bool,\n",
    "):\n",
    "\n",
    "    results_dict_df = {}\n",
    "\n",
    "    for stock in params[\"assetlist\"]:\n",
    "        results_dict_df[stock] = pd.DataFrame(\n",
    "            index=range_states, columns=[\"AIC\", \"BIC\"]\n",
    "        )\n",
    "        for nstate in range_states:\n",
    "            columns = generate_columns(stock, contains_vol, contains_USD)\n",
    "\n",
    "            insample_data = df[columns]\n",
    "\n",
    "            model = hmm.GaussianHMM(n_components=nstate, **param_dict, verbose=False)\n",
    "            results = model.fit(insample_data)\n",
    "\n",
    "            convergence = results.monitor_.converged\n",
    "            all_states_found = np.isclose(a=(model.transmat_.sum(axis=1)), b=1).all()\n",
    "            startprob_check = model.startprob_.sum() == 1\n",
    "            good_model = convergence and all_states_found and startprob_check\n",
    "\n",
    "            if good_model:\n",
    "                try:\n",
    "                    results_dict_df[stock].loc[nstate, \"AIC\"] = model.aic(insample_data)\n",
    "                    results_dict_df[stock].loc[nstate, \"BIC\"] = model.bic(insample_data)\n",
    "                except ValueError:\n",
    "                    pass\n",
    "\n",
    "            else:\n",
    "                print(\">\" * 10, f\"{stock} {nstate} did not converge\")\n",
    "                results_dict_df[stock].loc[nstate, \"AIC\"] = np.inf\n",
    "                results_dict_df[stock].loc[nstate, \"BIC\"] = np.inf\n",
    "\n",
    "    return results_dict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>> MERV_USD 7 did not converge\n",
      ">>>>>>>>>> GGAL.BA 5 did not converge\n",
      ">>>>>>>>>> GGAL.BA 7 did not converge\n",
      ">>>>>>>>>> GGAL 9 did not converge\n",
      ">>>>>>>>>> YPFD.BA 5 did not converge\n",
      ">>>>>>>>>> YPF 9 did not converge\n",
      ">>>>>>>>>> YPF 10 did not converge\n",
      ">>>>>>>>>> EDN.BA 6 did not converge\n",
      ">>>>>>>>>> BMA.BA 8 did not converge\n",
      ">>>>>>>>>> BMA 5 did not converge\n",
      ">>>>>>>>>> BBAR.BA 7 did not converge\n"
     ]
    }
   ],
   "source": [
    "results_dict_df_univ = fit_hmm_model(\n",
    "    df, params[\"assetlist\"], range_states, param_dict, contains_vol=False, contains_USD=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best_model(\n",
    "    df: pd.DataFrame,\n",
    "    results_dict: dict,\n",
    "    tickerlist: list,\n",
    "    param_dict: dict,\n",
    "    contains_vol: bool,\n",
    "    contains_USD: bool,\n",
    "):\n",
    "    \"\"\"\"\"\"\n",
    "    aic_best_model = {stock: None for stock in tickerlist}\n",
    "    bic_best_model = {stock: None for stock in tickerlist}\n",
    "\n",
    "    for stock in tickerlist:\n",
    "        columns = generate_columns(stock, contains_vol, contains_USD)\n",
    "        insample_data = df[columns]\n",
    "\n",
    "        best_aic_nstate = results_dict[stock][\"AIC\"].astype(float).idxmin()\n",
    "        best_bic_nstate = results_dict[stock][\"BIC\"].astype(float).idxmin()\n",
    "\n",
    "        print(\n",
    "            f\"For stock {stock}, best AIC: {best_aic_nstate} best BIC: {best_bic_nstate}\"\n",
    "        )\n",
    "\n",
    "        aic_best_model[stock] = hmm.GaussianHMM(\n",
    "            n_components=best_aic_nstate, **param_dict\n",
    "        ).fit(insample_data)\n",
    "\n",
    "        bic_best_model[stock] = hmm.GaussianHMM(\n",
    "            n_components=best_bic_nstate, **param_dict\n",
    "        ).fit(insample_data)\n",
    "\n",
    "    return aic_best_model, bic_best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For stock MERV_USD, best AIC: 4 best BIC: 4\n",
      "For stock ^MERV, best AIC: 4 best BIC: 4\n",
      "For stock GGAL.BA, best AIC: 4 best BIC: 3\n",
      "For stock GGAL, best AIC: 4 best BIC: 4\n",
      "For stock YPFD.BA, best AIC: 4 best BIC: 2\n",
      "For stock YPF, best AIC: 4 best BIC: 3\n",
      "For stock EDN.BA, best AIC: 4 best BIC: 3\n",
      "For stock EDN, best AIC: 5 best BIC: 4\n",
      "For stock BMA.BA, best AIC: 3 best BIC: 3\n",
      "For stock BMA, best AIC: 4 best BIC: 3\n",
      "For stock BBAR.BA, best AIC: 3 best BIC: 3\n",
      "For stock BBAR, best AIC: 4 best BIC: 3\n"
     ]
    }
   ],
   "source": [
    "aic_best_model_univ, bic_best_model_univ = select_best_model(\n",
    "    df=df,\n",
    "    results_dict=results_dict_df_univ,\n",
    "    tickerlist=params[\"assetlist\"],\n",
    "    param_dict=param_dict,\n",
    "    contains_vol=False,\n",
    "    contains_USD=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating out of sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = f'finaldf_test_{params[\"tablename\"]}.pickle'\n",
    "filename = os.path.join(dataroute, name)\n",
    "with open(filename, \"rb\") as handle:\n",
    "    df_test = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_residuals(actual: pd.DataFrame, forecasts: pd.DataFrame):\n",
    "    residuals = (actual - forecasts)\n",
    "    return residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_HMM_samples_residuals(model, insample_data, oos_data):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        model (_type_): _description_\n",
    "        insample_data (_type_): _description_\n",
    "        oos_data (_type_): _description_\n",
    "    \"\"\"\n",
    "    # pseudocodigo\n",
    "    # agarra el mejor modelo (esto con una cantidad optima de params ya esta)\n",
    "    # fittear t-j con t-j-252d\n",
    "    # Darle un año de datos hasta t-j para que me prediga la secuencia (probabilidad) de estados.\n",
    "    # Le pido que me prediga las probabilidades de cada estado durante el periodo t-j, t-j-252:\n",
    "    # esto me da una matriz de (252 x n estados)\n",
    "    # esto entiendo es https://hmmlearn.readthedocs.io/en/latest/api.html#hmmlearn.hmm.GaussianHMM.predict_proba\n",
    "    # Tomo la ultima fila de la matriz\n",
    "    # Multiplico esa por el vector de medias estimadas: este punto es mi forecast.\n",
    "    # esto es model.means_ (!)\n",
    "    nstate = model.n_components\n",
    "    columns = oos_data.columns\n",
    "\n",
    "    split_date = oos_data.index[0]\n",
    "    dates_to_forecast = len(oos_data.index)\n",
    "\n",
    "    probabilities = pd.DataFrame(columns=range(nstate), index=oos_data.index)\n",
    "    forecasts = pd.DataFrame(columns=oos_data.columns, index=oos_data.index)\n",
    "\n",
    "    full_data = pd.concat([insample_data, oos_data])\n",
    "    del insample_data\n",
    "\n",
    "    # vamos a implementar recursive window forecasting\n",
    "\n",
    "    index = full_data.index\n",
    "    end_loc = np.where(index >= split_date)[0].min()\n",
    "    # esto es un int del iloc\n",
    "    # preciso usar ints de iloc porque el timedelta se me va a romper con el fin de semana\n",
    "    rolling_window = 252\n",
    "\n",
    "    nstate = model.n_components\n",
    "    model = hmm.GaussianHMM(n_components=nstate, **param_dict, verbose=False)\n",
    "\n",
    "    model_list = []\n",
    "    counter = 0\n",
    "\n",
    "    for i in range(1, dates_to_forecast):\n",
    "        date_of_first_forecast = full_data.index[end_loc + i - 1]\n",
    "\n",
    "        fitstart = end_loc - rolling_window + i\n",
    "        fitend = end_loc + i\n",
    "\n",
    "        # fit model with last year\n",
    "        fit_data = full_data.iloc[fitstart:fitend][columns]\n",
    "        res = model.fit(fit_data)\n",
    "        model_list.append(res)\n",
    "\n",
    "        # obtenemos las probabilidades por estado del ultimo dia\n",
    "        # son las probabilidades que maximizan la log/likelihood de toda la secuencia\n",
    "        index = len(model_list)\n",
    "        while index > 0:\n",
    "            try:\n",
    "                add_count = False\n",
    "                last_day_state_probs = res.predict_proba(fit_data)[-1]\n",
    "                probabilities.loc[date_of_first_forecast] = last_day_state_probs\n",
    "                index = 0\n",
    "\n",
    "            except ValueError:\n",
    "                # this happens when startprob_ must sum to 1 (got nan)\n",
    "                # si el modelo falla en el predict_proba, se utiliza el de t-1\n",
    "                add_count = True\n",
    "                index = index - 1\n",
    "                res = model_list[index]\n",
    "\n",
    "                if not \"last_day_state_probs\" in locals():\n",
    "                    # this checks for failure of estimation in the first day\n",
    "                    last_day_state_probs = np.full(nstate, (1 / nstate))\n",
    "                    # inputs a flat prior if it has no previous day to fall back on\n",
    "\n",
    "        if add_count:\n",
    "            counter = counter + 1\n",
    "        # model.means_ es es la media condicional a cada estado\n",
    "        # cada columna representa cada columna del dataset\n",
    "        # cada fila es un estado\n",
    "        # el producto punto entre este y las probabilidades del ultimo día me da la media esperada por cada columna\n",
    "        expected_means = np.dot(last_day_state_probs, model.means_)\n",
    "        forecasts.loc[date_of_first_forecast] = expected_means\n",
    "\n",
    "    pct_nan = forecasts.iloc[:, 0].isna().sum() / len(forecasts.index) * 100\n",
    "\n",
    "    if pct_nan > 5:\n",
    "        warnings.warn(f\"{oos_data.columns[0]} % na: {pct_nan}\")\n",
    "\n",
    "    forecasts.fillna(method=\"ffill\", inplace=True)\n",
    "\n",
    "    residuals = return_residuals(oos_data, forecasts)\n",
    "\n",
    "    print(\"failed models: \", counter)\n",
    "    return probabilities, forecasts, residuals, counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_samples(\n",
    "    best_model_dict: dict,\n",
    "    modeltype: str,\n",
    "    criterion: str,\n",
    "    insample_data: pd.DataFrame,\n",
    "    oos_data: pd.DataFrame,\n",
    "    tickerlist: list,\n",
    "    contains_vol: bool,\n",
    "    contains_USD: bool,\n",
    "):\n",
    "    probabilities = {stock: None for stock in tickerlist}\n",
    "    forecasts = {stock: None for stock in tickerlist}\n",
    "    residuals = {stock: None for stock in tickerlist}\n",
    "    failed = {stock: None for stock in tickerlist}\n",
    "\n",
    "    print(\">\" * 10, modeltype, criterion)\n",
    "\n",
    "    for stock in tickerlist:\n",
    "        print(stock)\n",
    "        columns = generate_columns(\n",
    "            stock=stock, contains_vol=contains_vol, contains_USD=contains_USD\n",
    "        )\n",
    "\n",
    "        proba, fcast, resid, fails = generate_HMM_samples_residuals(\n",
    "            best_model_dict[stock],\n",
    "            insample_data=insample_data[columns],\n",
    "            oos_data=oos_data[columns],\n",
    "        )\n",
    "\n",
    "        probabilities[stock] = proba\n",
    "        forecasts[stock] = fcast\n",
    "        residuals[stock] = resid\n",
    "        failed[stock] = fails\n",
    "\n",
    "    save_as_pickle(\n",
    "        data=forecasts,\n",
    "        resultsroute=params[\"resultsroute\"],\n",
    "        model_type=f\"HMM_{modeltype}\",\n",
    "        tablename=params[\"tablename\"],\n",
    "        criterion=criterion,\n",
    "        type_save=\"forecasts\",\n",
    "    )\n",
    "\n",
    "    save_as_pickle(\n",
    "        data=residuals,\n",
    "        resultsroute=params[\"resultsroute\"],\n",
    "        model_type=f\"HMM_{modeltype}\",\n",
    "        tablename=params[\"tablename\"],\n",
    "        criterion=criterion,\n",
    "        type_save=\"residuals\",\n",
    "    )\n",
    "\n",
    "    save_as_pickle(\n",
    "        data=failed,\n",
    "        resultsroute=params[\"resultsroute\"],\n",
    "        model_type=f\"HMM_{modeltype}\",\n",
    "        tablename=params[\"tablename\"],\n",
    "        criterion=criterion,\n",
    "        type_save=\"model_fails\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict = {\n",
    "    \"aic\": {\n",
    "        \"univ\": (aic_best_model_univ, False, False)\n",
    "    },\n",
    "    \"bic\": {\n",
    "        \"univ\": (bic_best_model_univ, False, False)\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>> univ aic\n",
      "MERV_USD\n",
      "failed models:  0\n",
      "^MERV\n",
      "failed models:  0\n",
      "GGAL.BA\n",
      "failed models:  1\n",
      "GGAL\n",
      "failed models:  0\n",
      "YPFD.BA\n",
      "failed models:  0\n",
      "YPF\n",
      "failed models:  0\n",
      "EDN.BA\n",
      "failed models:  0\n",
      "EDN\n",
      "failed models:  0\n",
      "BMA.BA\n",
      "failed models:  0\n",
      "BMA\n",
      "failed models:  0\n",
      "BBAR.BA\n",
      "failed models:  0\n",
      "BBAR\n",
      "failed models:  0\n",
      ">>>>>>>>>> univ bic\n",
      "MERV_USD\n",
      "failed models:  0\n",
      "^MERV\n",
      "failed models:  0\n",
      "GGAL.BA\n",
      "failed models:  0\n",
      "GGAL\n",
      "failed models:  0\n",
      "YPFD.BA\n",
      "failed models:  0\n",
      "YPF\n",
      "failed models:  0\n",
      "EDN.BA\n",
      "failed models:  0\n",
      "EDN\n",
      "failed models:  0\n",
      "BMA.BA\n",
      "failed models:  0\n",
      "BMA\n",
      "failed models:  0\n",
      "BBAR.BA\n",
      "failed models:  0\n",
      "BBAR\n",
      "failed models:  0\n"
     ]
    }
   ],
   "source": [
    "for criterion, type_dict in models_dict.items():\n",
    "    for modeltype, tupla in type_dict.items():\n",
    "        best_dict, contains_vol, contains_USD = tupla\n",
    "        try:\n",
    "            generate_and_save_samples(\n",
    "                best_model_dict=best_dict,\n",
    "                modeltype=modeltype,\n",
    "                criterion=criterion,\n",
    "                insample_data=df,\n",
    "                oos_data=df_test,\n",
    "                tickerlist=params[\"assetlist\"],\n",
    "                contains_vol=contains_vol,\n",
    "                contains_USD=contains_USD,\n",
    "            )\n",
    "        except UnboundLocalError:\n",
    "            print(f\"MODEL FALILURE: {criterion}, {modeltype}\")"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
