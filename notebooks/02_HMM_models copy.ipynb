{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Startup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pomegranate as pm\n",
    "import torch\n",
    "from scipy.special import logsumexp\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pomegranate.distributions import Normal\n",
    "from pomegranate.hmm import DenseHMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "np.random.seed(random_state)\n",
    "# logging.captureWarnings(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.params import get_params\n",
    "from scripts.aux_functions import (\n",
    "    generate_columns,\n",
    "    save_as_pickle,\n",
    "    get_all_results_matching,\n",
    "    clean_modelname,\n",
    ")\n",
    "\n",
    "params = get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroute = params[\"dataroute\"]\n",
    "resultsroute = params[\"resultsroute\"]\n",
    "dumproute = params[\"dumproute\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = f'finaldf_train_{params[\"tablename\"]}.pickle'\n",
    "filename = os.path.join(dataroute, name)\n",
    "with open(filename, \"rb\") as handle:\n",
    "    df = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>^BVSP_rets</th>\n",
       "      <th>^BVSP_log_rets</th>\n",
       "      <th>^BVSP_gk_vol</th>\n",
       "      <th>VALE3.SA_rets</th>\n",
       "      <th>VALE3.SA_log_rets</th>\n",
       "      <th>VALE3.SA_gk_vol</th>\n",
       "      <th>VALE_rets</th>\n",
       "      <th>VALE_log_rets</th>\n",
       "      <th>VALE_gk_vol</th>\n",
       "      <th>PETR3.SA_rets</th>\n",
       "      <th>...</th>\n",
       "      <th>ABEV3.SA_gk_vol</th>\n",
       "      <th>ABEV_rets</th>\n",
       "      <th>ABEV_log_rets</th>\n",
       "      <th>ABEV_gk_vol</th>\n",
       "      <th>USD_rets</th>\n",
       "      <th>USD_log_rets</th>\n",
       "      <th>USD_gk_vol</th>\n",
       "      <th>^BVSP_USD_rets</th>\n",
       "      <th>^BVSP_USD_log_rets</th>\n",
       "      <th>^BVSP_USD_gk_vol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>0.012182</td>\n",
       "      <td>0.012109</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>-0.017007</td>\n",
       "      <td>-0.017153</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>-0.011168</td>\n",
       "      <td>-0.011231</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.037298</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.006920</td>\n",
       "      <td>0.006896</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.005423</td>\n",
       "      <td>0.005409</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.008609</td>\n",
       "      <td>0.008572</td>\n",
       "      <td>0.000218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>-0.012462</td>\n",
       "      <td>-0.012540</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>-0.015455</td>\n",
       "      <td>-0.015576</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>-0.008471</td>\n",
       "      <td>-0.008507</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.003401</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>-0.009110</td>\n",
       "      <td>-0.009152</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>-0.012968</td>\n",
       "      <td>-0.013053</td>\n",
       "      <td>0.000163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-07</th>\n",
       "      <td>-0.009437</td>\n",
       "      <td>-0.009481</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>-0.019681</td>\n",
       "      <td>-0.019878</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>-0.018510</td>\n",
       "      <td>-0.018683</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>-0.013075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>-0.007814</td>\n",
       "      <td>-0.007845</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.002544</td>\n",
       "      <td>0.002541</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>-0.004489</td>\n",
       "      <td>-0.004499</td>\n",
       "      <td>0.000180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-08</th>\n",
       "      <td>-0.012998</td>\n",
       "      <td>-0.013083</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>-0.007887</td>\n",
       "      <td>-0.007919</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>-0.014990</td>\n",
       "      <td>-0.015104</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>-0.028460</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.005967</td>\n",
       "      <td>0.005949</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.002794</td>\n",
       "      <td>0.002790</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>-0.017548</td>\n",
       "      <td>-0.017704</td>\n",
       "      <td>0.000250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-09</th>\n",
       "      <td>0.007378</td>\n",
       "      <td>0.007351</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.004577</td>\n",
       "      <td>0.004567</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.001964</td>\n",
       "      <td>0.001962</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.003096</td>\n",
       "      <td>0.003092</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.009302</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>0.000087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ^BVSP_rets  ^BVSP_log_rets  ^BVSP_gk_vol  VALE3.SA_rets  \\\n",
       "2013-01-03    0.012182        0.012109      0.000218      -0.017007   \n",
       "2013-01-04   -0.012462       -0.012540      0.000163      -0.015455   \n",
       "2013-01-07   -0.009437       -0.009481      0.000180      -0.019681   \n",
       "2013-01-08   -0.012998       -0.013083      0.000250      -0.007887   \n",
       "2013-01-09    0.007378        0.007351      0.000087       0.004577   \n",
       "\n",
       "            VALE3.SA_log_rets  VALE3.SA_gk_vol  VALE_rets  VALE_log_rets  \\\n",
       "2013-01-03          -0.017153         0.000190  -0.011168      -0.011231   \n",
       "2013-01-04          -0.015576         0.000512  -0.008471      -0.008507   \n",
       "2013-01-07          -0.019878         0.000541  -0.018510      -0.018683   \n",
       "2013-01-08          -0.007919         0.000184  -0.014990      -0.015104   \n",
       "2013-01-09           0.004567         0.000137   0.001964       0.001962   \n",
       "\n",
       "            VALE_gk_vol  PETR3.SA_rets  ...  ABEV3.SA_gk_vol  ABEV_rets  \\\n",
       "2013-01-03     0.000204       0.037298  ...         0.000185   0.006920   \n",
       "2013-01-04     0.000265       0.003401  ...         0.000270   0.000711   \n",
       "2013-01-07     0.000324      -0.013075  ...         0.000146  -0.007814   \n",
       "2013-01-08     0.000108      -0.028460  ...         0.000141   0.005967   \n",
       "2013-01-09     0.000136       0.010101  ...         0.000309   0.007117   \n",
       "\n",
       "            ABEV_log_rets  ABEV_gk_vol  USD_rets  USD_log_rets  USD_gk_vol  \\\n",
       "2013-01-03       0.006896     0.000123  0.005423      0.005409    0.000005   \n",
       "2013-01-04       0.000711     0.000056 -0.009110     -0.009152    0.000127   \n",
       "2013-01-07      -0.007845     0.000065  0.002544      0.002541    0.000056   \n",
       "2013-01-08       0.005949     0.000061  0.002794      0.002790    0.000030   \n",
       "2013-01-09       0.007092     0.000037  0.003096      0.003092    0.000028   \n",
       "\n",
       "            ^BVSP_USD_rets  ^BVSP_USD_log_rets  ^BVSP_USD_gk_vol  \n",
       "2013-01-03        0.008609            0.008572          0.000218  \n",
       "2013-01-04       -0.012968           -0.013053          0.000163  \n",
       "2013-01-07       -0.004489           -0.004499          0.000180  \n",
       "2013-01-08       -0.017548           -0.017704          0.000250  \n",
       "2013-01-09        0.009302            0.009259          0.000087  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HMM Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_states = range(1, 16)\n",
    "emptydf = pd.DataFrame(columns=[\"AIC\", \"BIC\"], index=range_states)\n",
    "emptydf.fillna(np.inf, inplace=True)\n",
    "results_dict_df = {stock: emptydf for stock in params[\"tickerlist\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_df_to_reshaped(data: pd.DataFrame):\n",
    "    npdata = data.values\n",
    "    data_reshaped = npdata[:, :, np.newaxis]\n",
    "    return data_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GaussianHMM(data_reshaped: np.ndarray, n_state: int):\n",
    "    model = DenseHMM(distributions=[Normal() for _ in range(n_state)], sample_length=1)\n",
    "\n",
    "    res = model.fit(data_reshaped)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_params(res: pm.hmm.dense_hmm.DenseHMM):\n",
    "    n_dist = res.n_distributions\n",
    "    params_from_dists = n_dist * 2  # mean and variance for Normal\n",
    "    transmat_elements = n_dist * (\n",
    "        n_dist - 1\n",
    "    )  # square matrix (minus last row bc must sum to one)\n",
    "    n_params = params_from_dists + transmat_elements\n",
    "    return n_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aic(res: pm.hmm.dense_hmm.DenseHMM, data: np.ndarray):\n",
    "    \"\"\"\n",
    "    Log Likelihood of the model is the Logsumexp of the log likelihood\n",
    "    see https://stats.stackexchange.com/questions/60902/how-to-calculate-the-log-likelihood-in-hmm-from-the-output-of-the-forward-algori\n",
    "    \"\"\"\n",
    "    aic = 2 * n_params(res) - 2 * logsumexp(res.log_probability(data))\n",
    "    return aic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bic(res: pm.hmm.dense_hmm.DenseHMM, data: np.ndarray):\n",
    "    \"\"\"\n",
    "    bic = k * np.log(len(data)) - 2 * model.log_likelihood(data)\n",
    "    \"\"\"\n",
    "    bic = n_params(res) * np.log(len(data)) - 2 * logsumexp(res.log_probability(data))\n",
    "    return bic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best(data: pd.DataFrame, max_states=15):\n",
    "\n",
    "    aic = {\"criterion\": np.inf, \"best_model\": None, \"n_state\": None}\n",
    "    bic = {\"criterion\": np.inf, \"best_model\": None, \"n_state\": None}\n",
    "\n",
    "    data_reshaped = from_df_to_reshaped(data)\n",
    "\n",
    "    for num_states in range(2, max_states + 1):\n",
    "        res = GaussianHMM(data_reshaped, n_state=num_states)\n",
    "\n",
    "        aic_result = get_aic(res, data_reshaped)\n",
    "        bic_result = get_bic(res, data_reshaped)\n",
    "\n",
    "        if aic_result < aic[\"criterion\"]:\n",
    "            aic[\"criterion\"] = aic_result\n",
    "            aic[\"best_model\"] = res\n",
    "            aic[\"n_state\"] = num_states\n",
    "        if bic_result < bic[\"criterion\"]:\n",
    "            bic[\"criterion\"] = bic_result\n",
    "            bic[\"best_model\"] = res\n",
    "            bic[\"n_state\"] = num_states\n",
    "\n",
    "    return aic, bic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_all_assets(\n",
    "    df: pd.DataFrame,\n",
    "    max_states: int = 10,\n",
    "    contains_vol: bool = False,\n",
    "    contains_USD: bool = False,\n",
    "):\n",
    "    best = {stock: {\"aic\": None, \"bic\": None} for stock in params[\"assetlist\"]}\n",
    "\n",
    "    for stock in params[\"assetlist\"]:\n",
    "        print(stock)\n",
    "        cols = generate_columns(\n",
    "            stock=stock, contains_vol=contains_vol, contains_USD=contains_USD\n",
    "        )\n",
    "        aic, bic = select_best(df[cols], max_states=max_states)\n",
    "        best[stock][\"aic\"] = aic\n",
    "        best[stock][\"bic\"] = bic\n",
    "\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"USD_^BVSP_log_rets\", \"USD_^BVSP_gk_vol\"]] = df[\n",
    "    [\"^BVSP_log_rets\", \"^BVSP_gk_vol\"]\n",
    "].copy()\n",
    "# transitorio pq issue #71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^BVSP\n",
      "USD_^BVSP\n",
      "VALE3.SA\n",
      "VALE\n",
      "PETR3.SA\n",
      "PBR\n",
      "EMBR3.SA\n",
      "ERJ\n",
      "ABEV3.SA\n",
      "ABEV\n"
     ]
    }
   ],
   "source": [
    "best_with_vol = find_best_all_assets(\n",
    "    df, max_states=10, contains_vol=True, contains_USD=False\n",
    ")\n",
    "# this cell sometimes crashes unexpectedly - just run again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^BVSP\n",
      "USD_^BVSP\n",
      "VALE3.SA\n",
      "VALE\n",
      "PETR3.SA\n",
      "PBR\n",
      "EMBR3.SA\n",
      "ERJ\n",
      "ABEV3.SA\n",
      "ABEV\n"
     ]
    }
   ],
   "source": [
    "best_multiv = find_best_all_assets(\n",
    "    df, max_states=10, contains_vol=True, contains_USD=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'^BVSP': {'aic': {'criterion': -32.508628845214844,\n",
       "   'best_model': DenseHMM(\n",
       "     (start): Silent()\n",
       "     (end): Silent()\n",
       "     (distributions): ModuleList(\n",
       "       (0-2): 3 x Normal()\n",
       "     )\n",
       "   ),\n",
       "   'n_state': 3},\n",
       "  'bic': {'criterion': 7.570280750408855,\n",
       "   'best_model': DenseHMM(\n",
       "     (start): Silent()\n",
       "     (end): Silent()\n",
       "     (distributions): ModuleList(\n",
       "       (0-1): 2 x Normal()\n",
       "     )\n",
       "   ),\n",
       "   'n_state': 2}},\n",
       " 'USD_^BVSP': {'aic': {'criterion': -32.511051177978516,\n",
       "   'best_model': DenseHMM(\n",
       "     (start): Silent()\n",
       "     (end): Silent()\n",
       "     (distributions): ModuleList(\n",
       "       (0-2): 3 x Normal()\n",
       "     )\n",
       "   ),\n",
       "   'n_state': 3},\n",
       "  'bic': {'criterion': 6.964316089764324,\n",
       "   'best_model': DenseHMM(\n",
       "     (start): Silent()\n",
       "     (end): Silent()\n",
       "     (distributions): ModuleList(\n",
       "       (0-1): 2 x Normal()\n",
       "     )\n",
       "   ),\n",
       "   'n_state': 2}},\n",
       " 'VALE3.SA': {'aic': {'criterion': -28.513328552246094,\n",
       "   'best_model': DenseHMM(\n",
       "     (start): Silent()\n",
       "     (end): Silent()\n",
       "     (distributions): ModuleList(\n",
       "       (0-2): 3 x Normal()\n",
       "     )\n",
       "   ),\n",
       "   'n_state': 3},\n",
       "  'bic': {'criterion': 9.876597126141277,\n",
       "   'best_model': DenseHMM(\n",
       "     (start): Silent()\n",
       "     (end): Silent()\n",
       "     (distributions): ModuleList(\n",
       "       (0-1): 2 x Normal()\n",
       "     )\n",
       "   ),\n",
       "   'n_state': 2}},\n",
       " 'VALE': {'aic': {'criterion': -27.807945251464844,\n",
       "   'best_model': DenseHMM(\n",
       "     (start): Silent()\n",
       "     (end): Silent()\n",
       "     (distributions): ModuleList(\n",
       "       (0-2): 3 x Normal()\n",
       "     )\n",
       "   ),\n",
       "   'n_state': 3},\n",
       "  'bic': {'criterion': 10.760084827557293,\n",
       "   'best_model': DenseHMM(\n",
       "     (start): Silent()\n",
       "     (end): Silent()\n",
       "     (distributions): ModuleList(\n",
       "       (0-1): 2 x Normal()\n",
       "     )\n",
       "   ),\n",
       "   'n_state': 2}},\n",
       " 'PETR3.SA': {'aic': {'criterion': -37.08443832397461,\n",
       "   'best_model': DenseHMM(\n",
       "     (start): Silent()\n",
       "     (end): Silent()\n",
       "     (distributions): ModuleList(\n",
       "       (0-1): 2 x Normal()\n",
       "     )\n",
       "   ),\n",
       "   'n_state': 2},\n",
       "  'bic': {'criterion': -1.9558232229798165,\n",
       "   'best_model': DenseHMM(\n",
       "     (start): Silent()\n",
       "     (end): Silent()\n",
       "     (distributions): ModuleList(\n",
       "       (0-1): 2 x Normal()\n",
       "     )\n",
       "   ),\n",
       "   'n_state': 2}},\n",
       " 'PBR': {'aic': {'criterion': -27.076568603515625,\n",
       "   'best_model': DenseHMM(\n",
       "     (start): Silent()\n",
       "     (end): Silent()\n",
       "     (distributions): ModuleList(\n",
       "       (0-2): 3 x Normal()\n",
       "     )\n",
       "   ),\n",
       "   'n_state': 3},\n",
       "  'bic': {'criterion': 11.510264118328777,\n",
       "   'best_model': DenseHMM(\n",
       "     (start): Silent()\n",
       "     (end): Silent()\n",
       "     (distributions): ModuleList(\n",
       "       (0-1): 2 x Normal()\n",
       "     )\n",
       "   ),\n",
       "   'n_state': 2}},\n",
       " 'EMBR3.SA': {'aic': {'criterion': -38.00058364868164,\n",
       "   'best_model': DenseHMM(\n",
       "     (start): Silent()\n",
       "     (end): Silent()\n",
       "     (distributions): ModuleList(\n",
       "       (0-1): 2 x Normal()\n",
       "     )\n",
       "   ),\n",
       "   'n_state': 2},\n",
       "  'bic': {'criterion': -2.8719685476868477,\n",
       "   'best_model': DenseHMM(\n",
       "     (start): Silent()\n",
       "     (end): Silent()\n",
       "     (distributions): ModuleList(\n",
       "       (0-1): 2 x Normal()\n",
       "     )\n",
       "   ),\n",
       "   'n_state': 2}},\n",
       " 'ERJ': {'aic': {'criterion': -29.115802764892578,\n",
       "   'best_model': DenseHMM(\n",
       "     (start): Silent()\n",
       "     (end): Silent()\n",
       "     (distributions): ModuleList(\n",
       "       (0-2): 3 x Normal()\n",
       "     )\n",
       "   ),\n",
       "   'n_state': 3},\n",
       "  'bic': {'criterion': 9.990736683026043,\n",
       "   'best_model': DenseHMM(\n",
       "     (start): Silent()\n",
       "     (end): Silent()\n",
       "     (distributions): ModuleList(\n",
       "       (0-1): 2 x Normal()\n",
       "     )\n",
       "   ),\n",
       "   'n_state': 2}},\n",
       " 'ABEV3.SA': {'aic': {'criterion': -41.90980529785156,\n",
       "   'best_model': DenseHMM(\n",
       "     (start): Silent()\n",
       "     (end): Silent()\n",
       "     (distributions): ModuleList(\n",
       "       (0-1): 2 x Normal()\n",
       "     )\n",
       "   ),\n",
       "   'n_state': 2},\n",
       "  'bic': {'criterion': -6.78119019685677,\n",
       "   'best_model': DenseHMM(\n",
       "     (start): Silent()\n",
       "     (end): Silent()\n",
       "     (distributions): ModuleList(\n",
       "       (0-1): 2 x Normal()\n",
       "     )\n",
       "   ),\n",
       "   'n_state': 2}},\n",
       " 'ABEV': {'aic': {'criterion': -29.615638732910156,\n",
       "   'best_model': DenseHMM(\n",
       "     (start): Silent()\n",
       "     (end): Silent()\n",
       "     (distributions): ModuleList(\n",
       "       (0-2): 3 x Normal()\n",
       "     )\n",
       "   ),\n",
       "   'n_state': 3},\n",
       "  'bic': {'criterion': 9.033083637371746,\n",
       "   'best_model': DenseHMM(\n",
       "     (start): Silent()\n",
       "     (end): Silent()\n",
       "     (distributions): ModuleList(\n",
       "       (0-1): 2 x Normal()\n",
       "     )\n",
       "   ),\n",
       "   'n_state': 2}}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_multiv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating out of sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = f'finaldf_test_{params[\"tablename\"]}.pickle'\n",
    "filename = os.path.join(dataroute, name)\n",
    "with open(filename, \"rb\") as handle:\n",
    "    df_test = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[[\"USD_^BVSP_log_rets\", \"USD_^BVSP_gk_vol\"]] = df_test[\n",
    "    [\"^BVSP_log_rets\", \"^BVSP_gk_vol\"]\n",
    "].copy()\n",
    "# transitorio pq issue #71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_residuals(actual: pd.DataFrame, forecasts: pd.DataFrame):\n",
    "    residuals = actual - forecasts\n",
    "    return residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples_residuals(n_state, insample_data, oos_data):\n",
    "    \"\"\"\n",
    "    This function only requires the number of normal distributions, which may be acquired from len(res.distributions)\n",
    "    \"\"\"\n",
    "    # res.predict_proba(data_reshaped)[-1] es la matriz de cada estado\n",
    "    columns = oos_data.columns\n",
    "\n",
    "    split_date = oos_data.index[0]\n",
    "    dates_to_forecast = len(oos_data.index)\n",
    "\n",
    "    probabilities = pd.DataFrame(columns=range(n_state), index=oos_data.index)\n",
    "    forecasts = pd.DataFrame(columns=oos_data.columns, index=oos_data.index)\n",
    "\n",
    "    full_data = pd.concat([insample_data, oos_data])\n",
    "    index = full_data.index\n",
    "    end_loc = np.where(index >= split_date)[0].min()\n",
    "    # esto es un int del iloc\n",
    "    # preciso usar ints de iloc porque el timedelta se me va a romper con el fin de semana\n",
    "    rolling_window = 252\n",
    "\n",
    "    model_list = []\n",
    "\n",
    "    for i in range(1, dates_to_forecast):\n",
    "        # recursive window forecasting\n",
    "        date_of_first_forecast = full_data.index[end_loc + i - 1]\n",
    "\n",
    "        fitstart = end_loc - rolling_window + i\n",
    "        fitend = end_loc + i\n",
    "\n",
    "        # fit model with last year\n",
    "        fit_data = full_data.iloc[fitstart:fitend][columns]\n",
    "        reshaped_fit_data= from_df_to_reshaped(fit_data)\n",
    "        \n",
    "        res = GaussianHMM(data_reshaped=reshaped_fit_data, n_state=n_state)\n",
    "        model_list.append(res)\n",
    "        \n",
    "        prob_matrix = res.predict_proba(data_reshaped)[-1]\n",
    "        \n",
    "        last_day_state_probs = prob_matrix.sum(axis=0) / prob_matrix.sum()\n",
    "        # hotfix véase https://github.com/alfsn/regime-switching-hmm/issues/72\n",
    "\n",
    "        probabilities.loc[date_of_first_forecast] = last_day_state_probs\n",
    "        \n",
    "        param_means = [dist.means for dist in res.distributions]\n",
    "\n",
    "        param_tensor = torch.cat(param_means, dim=0)\n",
    "\n",
    "        expected_means = torch.dot(prob_states, param_tensor)\n",
    "        \n",
    "        forecasts.loc[date_of_first_forecast] = expected_means\n",
    "\n",
    "    forecasts.fillna(method=\"ffill\", inplace=True)\n",
    "\n",
    "    residuals = return_residuals(oos_data, forecasts)\n",
    "\n",
    "    return probabilities, forecasts, residuals\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_samples(\n",
    "    best_model_dict: dict,\n",
    "    modeltype: str,\n",
    "    insample_data: pd.DataFrame,\n",
    "    oos_data: pd.DataFrame,\n",
    "    contains_vol: bool,\n",
    "    contains_USD: bool,\n",
    "):\n",
    "    generic_dict = {stock: None for stock in params[\"tickerlist\"]}\n",
    "    probabilities = {\"aic\": generic_dict.copy(), \"bic\": generic_dict.copy()}\n",
    "    forecasts = probabilities.copy()\n",
    "    residuals = probabilities.copy()\n",
    "\n",
    "    for stock in best_model_dict.keys():\n",
    "        for criterion, specific_model in best_model_dict[stock].items():\n",
    "            n_state = specific_model[\"n_state\"]\n",
    "            print(criterion, stock, n_state)\n",
    "            columns = generate_columns(\n",
    "                stock=stock, contains_vol=contains_vol, contains_USD=contains_USD\n",
    "            )\n",
    "\n",
    "            print(columns)\n",
    "            print(insample_data.values.shape)\n",
    "            print(oos_data.values.shape)\n",
    "            proba, fcast, resid= generate_samples_residuals(\n",
    "                n_state=n_state,\n",
    "                insample_data=insample_data[columns],\n",
    "                oos_data=oos_data[columns],\n",
    "            )\n",
    "\n",
    "            probabilities[stock] = proba\n",
    "            forecasts[stock] = fcast\n",
    "            residuals[stock] = resid\n",
    "\n",
    "        save_as_pickle(\n",
    "            data=forecasts,\n",
    "            resultsroute=params[\"resultsroute\"],\n",
    "            model_type=f\"HMM_{modeltype}\",\n",
    "            tablename=params[\"tablename\"],\n",
    "            criterion=criterion,\n",
    "            type_save=\"forecasts\",\n",
    "        )\n",
    "\n",
    "        save_as_pickle(\n",
    "            data=residuals,\n",
    "            resultsroute=params[\"resultsroute\"],\n",
    "            model_type=f\"HMM_{modeltype}\",\n",
    "            tablename=params[\"tablename\"],\n",
    "            criterion=criterion,\n",
    "            type_save=\"residuals\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aic ^BVSP 2\n",
      "['^BVSP_log_rets', '^BVSP_gk_vol']\n",
      "(2578, 35)\n",
      "(131, 35)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "inconsistent tensor size, expected tensor [3] and src [2] to have the same number of elements, but got 3 and 2 elements respectively",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[112], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mgenerate_and_save_samples\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbest_model_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbest_with_vol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodeltype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwith_vol\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43minsample_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43moos_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontains_vol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontains_USD\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[111], line 25\u001b[0m, in \u001b[0;36mgenerate_and_save_samples\u001b[1;34m(best_model_dict, modeltype, insample_data, oos_data, contains_vol, contains_USD)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(insample_data\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(oos_data\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 25\u001b[0m proba, fcast, resid\u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_samples_residuals\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43minsample_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minsample_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43moos_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moos_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m probabilities[stock] \u001b[38;5;241m=\u001b[39m proba\n\u001b[0;32m     32\u001b[0m forecasts[stock] \u001b[38;5;241m=\u001b[39m fcast\n",
      "Cell \u001b[1;32mIn[110], line 48\u001b[0m, in \u001b[0;36mgenerate_samples_residuals\u001b[1;34m(n_state, insample_data, oos_data)\u001b[0m\n\u001b[0;32m     44\u001b[0m     param_means \u001b[38;5;241m=\u001b[39m [dist\u001b[38;5;241m.\u001b[39mmeans \u001b[38;5;28;01mfor\u001b[39;00m dist \u001b[38;5;129;01min\u001b[39;00m res\u001b[38;5;241m.\u001b[39mdistributions]\n\u001b[0;32m     46\u001b[0m     param_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(param_means, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 48\u001b[0m     expected_means \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprob_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m     forecasts\u001b[38;5;241m.\u001b[39mloc[date_of_first_forecast] \u001b[38;5;241m=\u001b[39m expected_means\n\u001b[0;32m     52\u001b[0m forecasts\u001b[38;5;241m.\u001b[39mfillna(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mffill\u001b[39m\u001b[38;5;124m\"\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: inconsistent tensor size, expected tensor [3] and src [2] to have the same number of elements, but got 3 and 2 elements respectively"
     ]
    }
   ],
   "source": [
    "generate_and_save_samples(\n",
    "    best_model_dict=best_with_vol,\n",
    "    modeltype= \"with_vol\",\n",
    "    insample_data=df,\n",
    "    oos_data=df_test,\n",
    "    contains_vol= True,\n",
    "    contains_USD=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict = {\n",
    "    \"with_vol\": (best_with_vol, True, False),\n",
    "    \"multiv\": (best_multiv, True, True)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^BVSP aic 2\n",
      "^BVSP bic 2\n",
      "USD_^BVSP aic 2\n",
      "USD_^BVSP bic 2\n",
      "VALE3.SA aic 2\n",
      "VALE3.SA bic 2\n",
      "VALE aic 2\n",
      "VALE bic 2\n",
      "PETR3.SA aic 2\n",
      "PETR3.SA bic 2\n",
      "PBR aic 2\n",
      "PBR bic 2\n",
      "EMBR3.SA aic 2\n",
      "EMBR3.SA bic 2\n",
      "ERJ aic 2\n",
      "ERJ bic 2\n",
      "ABEV3.SA aic 2\n",
      "ABEV3.SA bic 2\n",
      "ABEV aic 2\n",
      "ABEV bic 2\n",
      "^BVSP aic 3\n",
      "^BVSP bic 2\n",
      "USD_^BVSP aic 3\n",
      "USD_^BVSP bic 2\n",
      "VALE3.SA aic 3\n",
      "VALE3.SA bic 2\n",
      "VALE aic 3\n",
      "VALE bic 2\n",
      "PETR3.SA aic 2\n",
      "PETR3.SA bic 2\n",
      "PBR aic 3\n",
      "PBR bic 2\n",
      "EMBR3.SA aic 2\n",
      "EMBR3.SA bic 2\n",
      "ERJ aic 3\n",
      "ERJ bic 2\n",
      "ABEV3.SA aic 2\n",
      "ABEV3.SA bic 2\n",
      "ABEV aic 3\n",
      "ABEV bic 2\n"
     ]
    }
   ],
   "source": [
    "for modeltype, tupla in models_dict.items():\n",
    "    best_model_dict, contains_vol, contains_USD = tupla\n",
    "    generate_and_save_samples()            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>> univ aic\n",
      "^BVSP\n",
      "failed models:  0\n",
      "VALE3.SA\n",
      "failed models:  0\n",
      "VALE\n",
      "failed models:  0\n",
      "PETR3.SA\n",
      "failed models:  0\n",
      "PBR\n",
      "failed models:  0\n",
      "EMBR3.SA\n",
      "failed models:  0\n",
      "ERJ\n",
      "failed models:  0\n",
      "ABEV3.SA\n",
      "failed models:  0\n",
      "ABEV\n",
      "failed models:  0\n",
      ">>>>>>>>>> with_vol aic\n",
      "^BVSP\n",
      "failed models:  0\n",
      "VALE3.SA\n",
      "failed models:  0\n",
      "VALE\n",
      "failed models:  0\n",
      "PETR3.SA\n",
      "failed models:  0\n",
      "PBR\n",
      "failed models:  0\n",
      "EMBR3.SA\n",
      "failed models:  0\n",
      "ERJ\n",
      "failed models:  0\n",
      "ABEV3.SA\n",
      "failed models:  0\n",
      "ABEV\n",
      "failed models:  0\n",
      ">>>>>>>>>> multiv aic\n",
      "^BVSP\n",
      "failed models:  0\n",
      "VALE3.SA\n",
      "failed models:  3\n",
      "VALE\n",
      "failed models:  0\n",
      "PETR3.SA\n",
      "failed models:  0\n",
      "PBR\n",
      "failed models:  0\n",
      "EMBR3.SA\n",
      "failed models:  0\n",
      "ERJ\n",
      "failed models:  0\n",
      "ABEV3.SA\n",
      "failed models:  0\n",
      "ABEV\n",
      "failed models:  0\n",
      ">>>>>>>>>> univ bic\n",
      "^BVSP\n",
      "failed models:  0\n",
      "VALE3.SA\n",
      "failed models:  0\n",
      "VALE\n",
      "failed models:  0\n",
      "PETR3.SA\n",
      "failed models:  0\n",
      "PBR\n",
      "failed models:  0\n",
      "EMBR3.SA\n",
      "failed models:  0\n",
      "ERJ\n",
      "failed models:  0\n",
      "ABEV3.SA\n",
      "failed models:  0\n",
      "ABEV\n",
      "failed models:  0\n",
      ">>>>>>>>>> with_vol bic\n",
      "^BVSP\n",
      "failed models:  0\n",
      "VALE3.SA\n",
      "failed models:  0\n",
      "VALE\n",
      "failed models:  0\n",
      "PETR3.SA\n",
      "failed models:  0\n",
      "PBR\n",
      "failed models:  0\n",
      "EMBR3.SA\n",
      "failed models:  0\n",
      "ERJ\n",
      "failed models:  0\n",
      "ABEV3.SA\n",
      "failed models:  0\n",
      "ABEV\n",
      "failed models:  0\n",
      ">>>>>>>>>> multiv bic\n",
      "^BVSP\n",
      "failed models:  0\n",
      "VALE3.SA\n",
      "failed models:  3\n",
      "VALE\n",
      "failed models:  0\n",
      "PETR3.SA\n",
      "failed models:  0\n",
      "PBR\n",
      "failed models:  0\n",
      "EMBR3.SA\n",
      "failed models:  0\n",
      "ERJ\n",
      "failed models:  0\n",
      "ABEV3.SA\n",
      "failed models:  0\n",
      "ABEV\n",
      "failed models:  0\n"
     ]
    }
   ],
   "source": [
    "for criterion, type_dict in models_dict.items():\n",
    "    for modeltype, tupla in type_dict.items():\n",
    "        best_dict, contains_vol, contains_USD = tupla\n",
    "        try:\n",
    "            generate_and_save_samples(\n",
    "                best_model_dict=best_dict,\n",
    "                modeltype=modeltype,\n",
    "                criterion=criterion,\n",
    "                insample_data=df,\n",
    "                oos_data=df_test,\n",
    "                tickerlist=params[\"tickerlist\"],\n",
    "                contains_vol=contains_vol,\n",
    "                contains_USD=contains_USD,\n",
    "            )\n",
    "        except UnboundLocalError:\n",
    "            print(f\"MODEL FALILURE: {criterion}, {modeltype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = f\"\"\"HMM_multiv_{params[\"tablename\"]}_aic_best_residuals.pickle\"\"\"\n",
    "with open(os.path.join(resultsroute, file), \"rb\") as f:\n",
    "    opened_pickle = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>^BVSP_log_rets</th>\n",
       "      <th>^BVSP_gk_vol</th>\n",
       "      <th>USD_log_rets</th>\n",
       "      <th>USD_gk_vol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-12-01</th>\n",
       "      <td>0.005412</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>-0.007433</td>\n",
       "      <td>-0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-04</th>\n",
       "      <td>-0.010738</td>\n",
       "      <td>-0.000073</td>\n",
       "      <td>0.012951</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-05</th>\n",
       "      <td>0.000191</td>\n",
       "      <td>-0.000159</td>\n",
       "      <td>-0.002534</td>\n",
       "      <td>-0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-06</th>\n",
       "      <td>-0.010660</td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>-0.004736</td>\n",
       "      <td>-0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-07</th>\n",
       "      <td>0.002553</td>\n",
       "      <td>-0.000152</td>\n",
       "      <td>0.000697</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ^BVSP_log_rets  ^BVSP_gk_vol  USD_log_rets  USD_gk_vol\n",
       "2023-12-01        0.005412     -0.000107     -0.007433   -0.000024\n",
       "2023-12-04       -0.010738     -0.000073      0.012951    0.000010\n",
       "2023-12-05        0.000191     -0.000159     -0.002534   -0.000028\n",
       "2023-12-06       -0.010660     -0.000033     -0.004736   -0.000008\n",
       "2023-12-07        0.002553     -0.000152      0.000697    0.000005"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opened_pickle[params[\"index\"]].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'HMM_multiv_BR_^BVSP_aic_best_model_fails.pickle': '..\\\\results\\\\BR_^BVSP\\\\HMM_multiv_BR_^BVSP_aic_best_model_fails.pickle', 'HMM_multiv_BR_^BVSP_bic_best_model_fails.pickle': '..\\\\results\\\\BR_^BVSP\\\\HMM_multiv_BR_^BVSP_bic_best_model_fails.pickle', 'HMM_univ_BR_^BVSP_aic_best_model_fails.pickle': '..\\\\results\\\\BR_^BVSP\\\\HMM_univ_BR_^BVSP_aic_best_model_fails.pickle', 'HMM_univ_BR_^BVSP_bic_best_model_fails.pickle': '..\\\\results\\\\BR_^BVSP\\\\HMM_univ_BR_^BVSP_bic_best_model_fails.pickle', 'HMM_with_vol_BR_^BVSP_aic_best_model_fails.pickle': '..\\\\results\\\\BR_^BVSP\\\\HMM_with_vol_BR_^BVSP_aic_best_model_fails.pickle', 'HMM_with_vol_BR_^BVSP_bic_best_model_fails.pickle': '..\\\\results\\\\BR_^BVSP\\\\HMM_with_vol_BR_^BVSP_bic_best_model_fails.pickle'}\n"
     ]
    }
   ],
   "source": [
    "fails_dict = get_all_results_matching(resultsroute, [\"fail\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fails_df = pd.DataFrame()\n",
    "for name, dir in fails_dict.items():\n",
    "    dict_with_dfs = pd.read_pickle(dir)\n",
    "    colname = clean_modelname(\n",
    "        name, substring_to_replace=\"model_fails\", tablename=params[\"tablename\"]\n",
    "    )\n",
    "    fails_df[colname] = dict_with_dfs\n",
    "    os.remove(dir)\n",
    "\n",
    "fails_df = fails_df / len(df_test.index)\n",
    "fails_df.to_csv(\n",
    "    path_or_buf=os.path.join(\n",
    "        params[\"resultsroute\"], f\"\"\"HMM_{params[\"tablename\"]}_fails.csv\"\"\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graficando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_close_rets_vol(model, data, key, IC):\n",
    "    prediction = model.predict(data)\n",
    "    states = set(prediction)\n",
    "\n",
    "    fig = plt.figure(figsize=(20, 20))\n",
    "    plt.tight_layout()\n",
    "    plt.title(\n",
    "        f\"{key} Log returns and intraday Vol\\n{model.n_components} states / best by {IC}\"\n",
    "    )\n",
    "\n",
    "    for subplot, var in zip(range(1, 3), data.columns):\n",
    "        plt.subplot(2, 1, subplot)\n",
    "        for i in set(prediction):\n",
    "            state = prediction == i\n",
    "            x = data.index[state]\n",
    "            y = data[var].iloc[state]\n",
    "            plt.plot(x, y, \".\")\n",
    "        plt.legend(states, fontsize=16)\n",
    "\n",
    "        plt.grid(True)\n",
    "        plt.xlabel(\"datetime\", fontsize=16)\n",
    "        plt.ylabel(var, fontsize=16)\n",
    "\n",
    "    plt.savefig(os.path.join(resultsroute, \"graphs\", f\"HMM\", f\"{key}_model_{IC}.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for dictionary, IC in zip([aic_best_model, bic_best_model], [\"AIC\", \"BIC\"]):\n",
    "#    for key, model in dictionary.items():\n",
    "#        columns = [f\"{stock}_log_rets\", f\"{stock}_gk_vol\"]\n",
    "#        insample_data = df[columns]\n",
    "#        oos_data = df_test[columns]\n",
    "#        train_end = insample_data.index.max()\n",
    "#        data = pd.concat([insample_data, oos_data])\n",
    "#\n",
    "#        plot_close_rets_vol(model, data, key, IC)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
