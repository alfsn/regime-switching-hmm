{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53f032f0",
   "metadata": {},
   "source": [
    "# Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eba1443",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94baead",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.params import get_params\n",
    "from scripts.aux_functions import get_all_results_matching, subset_of_columns, clean_modelname\n",
    "\n",
    "params = get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904542a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroute = params[\"dataroute\"]\n",
    "resultsroute = params[\"resultsroute\"]\n",
    "dumproute = params[\"dumproute\"]\n",
    "graphsroute = params[\"graphsroute\"]\n",
    "dmroute=params[\"dmroute\"]\n",
    "gwroute=params[\"gwroute\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260608bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_test = params[\"start_test\"]\n",
    "local_suffix = params[\"local_suffix\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595cbc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = f'finaldf_test_{params[\"tablename\"]}.pickle'\n",
    "filename = os.path.join(dataroute, name)\n",
    "with open(filename, \"rb\") as handle:\n",
    "    df_test = pickle.load(handle)\n",
    "    \n",
    "df_test.index=pd.to_datetime(df_test.index.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e9fb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_forecasts = get_all_results_matching(params[\"resultsroute\"], [\"best_forecast\"])\n",
    "all_residuals = get_all_results_matching(params[\"resultsroute\"], [\"best_residuals\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9947de48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_pickle_route(route:str):\n",
    "    with open(route, \"rb\") as file:\n",
    "        dictionary = pickle.load(file)\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e21581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prefix(picklename:str):\n",
    "    picklename=picklename.replace(f\"\"\"{params[\"tablename\"]}_\"\"\", \"\").replace(\".pickle\", \"\").replace(\"_residuals\", \"\").replace(\"_forecasts\", \"\").replace(\"best\", \"\")\n",
    "    return picklename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124828fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_dictionary(dictionary:dict, prefix:str):\n",
    "    colname_list=[]\n",
    "    df_list=[]\n",
    "    for key, value in dictionary.items():\n",
    "        value.index = pd.to_datetime(value.index)\n",
    "        value = subset_of_columns(value, \"log_rets\", \"USD\")\n",
    "        \n",
    "        df_list.append(value)\n",
    "        \n",
    "        colname = prefix + key\n",
    "        colname_list.append(colname)\n",
    "    \n",
    "    pickledf = pd.concat(df_list, axis=1, join=\"outer\")\n",
    "    pickledf.columns = colname_list\n",
    "    \n",
    "    return pickledf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4704932c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_single_pickle(picklename:str, pickleroute:str):\n",
    "    prefix = create_prefix(picklename)\n",
    "    dictionary = open_pickle_route(pickleroute)\n",
    "    pickledf = concat_dictionary(dictionary, prefix)\n",
    "    return pickledf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145f3969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_dict(dictionary:dict):\n",
    "    pickledf_list=[]\n",
    "    for picklename, pickleroute in dictionary.items():\n",
    "        pickledf = aggregate_single_pickle(picklename, pickleroute)\n",
    "        pickledf_list.append(pickledf)\n",
    "    aggdf = pd.concat(pickledf_list, axis=1, join=\"outer\")\n",
    "    \n",
    "    return aggdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5297d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts = aggregate_dict(all_forecasts)\n",
    "residuals = aggregate_dict(all_residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329b1f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_date=pd.to_datetime(params[\"start_test\"])+pd.Timedelta(days=1)\n",
    "higher_date=pd.to_datetime(params[\"end_test\"])-pd.Timedelta(days=1)\n",
    "\n",
    "forecasts_df=forecasts[lower_date:higher_date].copy()\n",
    "residual_df=residuals[lower_date:higher_date].copy()\n",
    "df_test = df_test[lower_date:higher_date].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e41ccf",
   "metadata": {},
   "source": [
    "## Separating in different stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42c59ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_by_stock(df:pd.DataFrame):\n",
    "     stock_dict={}\n",
    "\n",
    "     for stock in params[\"assetlist\"]:\n",
    "          if params[\"local_suffix\"] in stock:\n",
    "               stock_dict[stock]= subset_of_columns(residual_df, stock)\n",
    "          else:\n",
    "               stock_dict[stock]= subset_of_columns(residual_df, stock, params[\"local_suffix\"])    \n",
    "     \n",
    "     return stock_dict      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454c8244",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts_by_stock=separate_by_stock(forecasts_df)\n",
    "residuals_by_stock=separate_by_stock(residual_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a5eebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_clean, name in zip([forecasts_by_stock, residuals_by_stock], [\"forecasts\", \"residuals\"]):\n",
    "    bystockname = name + \"_by_stock_\" + params[\"tablename\"] + \".pickle\"\n",
    "    with open(os.path.join(resultsroute, bystockname), \"wb\") as handle:\n",
    "        pickle.dump(df_clean, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d23faf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_in_column_names(df:pd.DataFrame, string:str):\n",
    "    new_cols=[]\n",
    "    for col in df.columns:\n",
    "        col=col.replace(string, \"\")\n",
    "        new_cols.append(col)\n",
    "    df=df.set_axis(labels=new_cols, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce28875e",
   "metadata": {},
   "source": [
    "# Fluctiation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b574a235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fluctuation_test(real_values, forecast_1, forecast_2, window=60, loss=\"mse\", significance_level=0.05):\n",
    "    \"\"\"\n",
    "    Giacomini-Rossi Fluctuation Test for forecast comparison with symmetric critical value bands.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame with test_stat, upper_crit, lower_crit\n",
    "    \"\"\"\n",
    "    assert len(real_values) == len(forecast_1) == len(forecast_2), \"Input series must have equal length\"\n",
    "\n",
    "    # Compute loss differential\n",
    "    if loss == \"mse\":\n",
    "        d_t = (real_values - forecast_1)**2 - (real_values - forecast_2)**2\n",
    "    elif loss == \"mae\":\n",
    "        d_t = np.abs(real_values - forecast_1) - np.abs(real_values - forecast_2)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported loss function.\")\n",
    "\n",
    "    test_stats = []\n",
    "    upper_crit = []\n",
    "    lower_crit = []\n",
    "    dates = []\n",
    "\n",
    "    z = norm.ppf(1 - significance_level / 2)  # two-sided\n",
    "\n",
    "    for i in range(window, len(d_t)):\n",
    "        d_window = d_t.iloc[i - window:i]\n",
    "        mean = d_window.mean()\n",
    "        std = d_window.std(ddof=1)\n",
    "        stat = np.sqrt(window) * mean / std\n",
    "\n",
    "        test_stats.append(stat)\n",
    "        upper_crit.append(z)\n",
    "        lower_crit.append(-z)\n",
    "        dates.append(d_t.index[i])\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        \"test_stat\": test_stats,\n",
    "        \"upper_crit\": upper_crit,\n",
    "        \"lower_crit\": lower_crit\n",
    "    }, index=dates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6c8aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fluctuation_test(result_df, title=\"\", savefig=False, path=\"\", filename=\"fluctuation_test\"):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(result_df.index, result_df[\"test_stat\"], label=\"Test Statistic\", color=\"blue\")\n",
    "    plt.axhline(y=result_df[\"upper_crit\"].iloc[0], linestyle=\"--\", color=\"red\", label=\"Upper Critical Value\")\n",
    "    plt.axhline(y=result_df[\"lower_crit\"].iloc[0], linestyle=\"--\", color=\"green\", label=\"Lower Critical Value\")\n",
    "    plt.fill_between(result_df.index, result_df[\"lower_crit\"], result_df[\"upper_crit\"], color=\"gray\", alpha=0.1, label=\"Non-rejection Region\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Fluctuation Test Statistic\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if savefig:\n",
    "        plt.savefig(os.path.join(path, filename + \".png\"), dpi=300)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95b0c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_to_test=[\"^BVSP\", \"BVSP_FX\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9170296b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for stock in subset_to_test:\n",
    "    real_values = subset_of_columns(df_test, f\"{stock}_log_rets\").squeeze()\n",
    "    forecasts = delete_in_column_names(forecasts_by_stock[stock].fillna(0), f\"_{stock}\")\n",
    "\n",
    "    columns = forecasts.columns\n",
    "    for i in range(len(columns)):\n",
    "        for j in range(i+1, len(columns)):\n",
    "            model1, model2 = columns[i], columns[j]\n",
    "            result = fluctuation_test(real_values, forecasts[model1], forecasts[model2], window=60, loss=\"mse\")\n",
    "            title = f\"Fluctuation Test: {stock} {model1} vs {model2}\"\n",
    "            plot_fluctuation_test(result, title=title, savefig=True, path=gwroute, filename=f\"{stock}_{model1}_vs_{model2}\")\n"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
