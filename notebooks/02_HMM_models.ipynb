{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Startup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from hmmlearn import hmm\n",
    "\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=42\n",
    "np.random.seed(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.params import get_params\n",
    "\n",
    "params = get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroute=os.path.join(\"..\",  \"data\")\n",
    "dumproute=os.path.join(\"..\",  \"dump\")\n",
    "resultsroute=os.path.join(\"..\",  \"results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=f'finaldf_train_{params[\"tablename\"]}.pickle'\n",
    "filename=os.path.join(dataroute, name)\n",
    "with open(filename, 'rb') as handle:\n",
    "    df=pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>^MERV_rets</th>\n",
       "      <th>^MERV_log_rets</th>\n",
       "      <th>^MERV_gk_vol</th>\n",
       "      <th>GGAL.BA_rets</th>\n",
       "      <th>GGAL.BA_log_rets</th>\n",
       "      <th>GGAL.BA_gk_vol</th>\n",
       "      <th>GGAL_rets</th>\n",
       "      <th>GGAL_log_rets</th>\n",
       "      <th>GGAL_gk_vol</th>\n",
       "      <th>YPFD.BA_rets</th>\n",
       "      <th>...</th>\n",
       "      <th>BBAR.BA_gk_vol</th>\n",
       "      <th>BBAR_rets</th>\n",
       "      <th>BBAR_log_rets</th>\n",
       "      <th>BBAR_gk_vol</th>\n",
       "      <th>USD_rets</th>\n",
       "      <th>USD_log_rets</th>\n",
       "      <th>USD_gk_vol</th>\n",
       "      <th>USD_^MERV_rets</th>\n",
       "      <th>USD_^MERV_log_rets</th>\n",
       "      <th>USD_^MERV_gk_vol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>0.007552</td>\n",
       "      <td>0.007524</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.010616</td>\n",
       "      <td>0.010560</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>-0.012748</td>\n",
       "      <td>-0.012830</td>\n",
       "      <td>0.001228</td>\n",
       "      <td>-0.006862</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>-0.005725</td>\n",
       "      <td>-0.005742</td>\n",
       "      <td>0.000960</td>\n",
       "      <td>0.008830</td>\n",
       "      <td>0.008792</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.001247</td>\n",
       "      <td>0.001246</td>\n",
       "      <td>0.000129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>0.007092</td>\n",
       "      <td>0.007067</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>-0.006303</td>\n",
       "      <td>-0.006323</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>-0.010043</td>\n",
       "      <td>-0.010094</td>\n",
       "      <td>0.000554</td>\n",
       "      <td>0.004936</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>-0.019194</td>\n",
       "      <td>-0.019381</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>0.018043</td>\n",
       "      <td>0.017883</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>-0.005727</td>\n",
       "      <td>-0.005744</td>\n",
       "      <td>0.000158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-07</th>\n",
       "      <td>-0.001035</td>\n",
       "      <td>-0.001035</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.002114</td>\n",
       "      <td>0.002112</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>-0.014493</td>\n",
       "      <td>-0.014599</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.010805</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>0.015656</td>\n",
       "      <td>0.015534</td>\n",
       "      <td>0.000511</td>\n",
       "      <td>-0.002489</td>\n",
       "      <td>-0.002492</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>-0.009769</td>\n",
       "      <td>-0.009817</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-08</th>\n",
       "      <td>0.008285</td>\n",
       "      <td>0.008251</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>-0.008439</td>\n",
       "      <td>-0.008475</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>-0.016176</td>\n",
       "      <td>-0.016309</td>\n",
       "      <td>0.001085</td>\n",
       "      <td>0.049563</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>-0.015414</td>\n",
       "      <td>-0.015534</td>\n",
       "      <td>0.000642</td>\n",
       "      <td>0.015356</td>\n",
       "      <td>0.015239</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>-0.001117</td>\n",
       "      <td>-0.001118</td>\n",
       "      <td>0.000082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-09</th>\n",
       "      <td>0.017826</td>\n",
       "      <td>0.017669</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011958</td>\n",
       "      <td>0.011887</td>\n",
       "      <td>0.005238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.003914</td>\n",
       "      <td>-0.003921</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>-0.008671</td>\n",
       "      <td>-0.008709</td>\n",
       "      <td>0.001065</td>\n",
       "      <td>0.017245</td>\n",
       "      <td>0.017098</td>\n",
       "      <td>0.000273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ^MERV_rets  ^MERV_log_rets  ^MERV_gk_vol  GGAL.BA_rets  \\\n",
       "2013-01-03    0.007552        0.007524      0.000129      0.010616   \n",
       "2013-01-04    0.007092        0.007067      0.000158     -0.006303   \n",
       "2013-01-07   -0.001035       -0.001035      0.000022      0.002114   \n",
       "2013-01-08    0.008285        0.008251      0.000082     -0.008439   \n",
       "2013-01-09    0.017826        0.017669      0.000273      0.000000   \n",
       "\n",
       "            GGAL.BA_log_rets  GGAL.BA_gk_vol  GGAL_rets  GGAL_log_rets  \\\n",
       "2013-01-03          0.010560        0.000677  -0.012748      -0.012830   \n",
       "2013-01-04         -0.006323        0.000208  -0.010043      -0.010094   \n",
       "2013-01-07          0.002112        0.000063  -0.014493      -0.014599   \n",
       "2013-01-08         -0.008475        0.000153  -0.016176      -0.016309   \n",
       "2013-01-09          0.000000        0.000000   0.011958       0.011887   \n",
       "\n",
       "            GGAL_gk_vol  YPFD.BA_rets  ...  BBAR.BA_gk_vol  BBAR_rets  \\\n",
       "2013-01-03     0.001228     -0.006862  ...        0.000169  -0.005725   \n",
       "2013-01-04     0.000554      0.004936  ...        0.000406  -0.019194   \n",
       "2013-01-07     0.000517      0.010805  ...        0.000492   0.015656   \n",
       "2013-01-08     0.001085      0.049563  ...        0.000438  -0.015414   \n",
       "2013-01-09     0.005238      0.000000  ...        0.000000  -0.003914   \n",
       "\n",
       "            BBAR_log_rets  BBAR_gk_vol  USD_rets  USD_log_rets  USD_gk_vol  \\\n",
       "2013-01-03      -0.005742     0.000960  0.008830      0.008792    0.000014   \n",
       "2013-01-04      -0.019381     0.000635  0.018043      0.017883    0.000133   \n",
       "2013-01-07       0.015534     0.000511 -0.002489     -0.002492    0.000048   \n",
       "2013-01-08      -0.015534     0.000642  0.015356      0.015239    0.000064   \n",
       "2013-01-09      -0.003921     0.000147 -0.008671     -0.008709    0.001065   \n",
       "\n",
       "            USD_^MERV_rets  USD_^MERV_log_rets  USD_^MERV_gk_vol  \n",
       "2013-01-03        0.001247            0.001246          0.000129  \n",
       "2013-01-04       -0.005727           -0.005744          0.000158  \n",
       "2013-01-07       -0.009769           -0.009817          0.000022  \n",
       "2013-01-08       -0.001117           -0.001118          0.000082  \n",
       "2013-01-09        0.017245            0.017098          0.000273  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickerlist=params[\"tickerlist\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HMM Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_states=range(1,16)\n",
    "emptydf=pd.DataFrame(columns=[\"AIC\", \"BIC\"], index=range_states)\n",
    "emptydf.fillna(np.inf, inplace=True)\n",
    "results_dict_df={stock:emptydf for stock in tickerlist}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "aic_best_model={stock:None for stock in tickerlist}\n",
    "bic_best_model={stock:None for stock in tickerlist}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stock in tickerlist:\n",
    "    columns = [f'{stock}_log_rets', f'{stock}_gk_vol']\n",
    "    insample_data = df[columns]\n",
    "\n",
    "    param_dict={\n",
    "        \"covariance_type\" : \"diag\", \n",
    "        \"n_iter\" : 500,\n",
    "        \"random_state\" : random_state\n",
    "        #no voy a usar startprob_prior por devlog 20-06-23\n",
    "        }\n",
    "\n",
    "    for nstate in range_states:\n",
    "        model = hmm.GaussianHMM(n_components= nstate, **param_dict, verbose=False)\n",
    "        results = model.fit(insample_data)\n",
    "\n",
    "        convergence=results.monitor_.converged\n",
    "        # esta es la condición de si el modelo convergió\n",
    "\n",
    "        all_states_found=np.isclose(a=(model.transmat_.sum(axis=1)), b=1).all()\n",
    "        # esta es la condición de que todos los estados (nstates) hayan sido observados\n",
    "        # si no, alguna fila en la matriz de transición del modelo son 0.\n",
    "        # el errormsg es \"Some rows of transmat_ have zero sum because no transition from the state was ever observed\".\n",
    "\n",
    "        startprob_check = (model.startprob_.sum()==1)\n",
    "        # esta es la condición de que los estados al inicializar estén definidos\n",
    "        \n",
    "        good_model = convergence and all_states_found and startprob_check\n",
    "\n",
    "        if good_model:\n",
    "            try:\n",
    "                results_dict_df[stock].loc[nstate, \"AIC\"]=model.aic(insample_data)\n",
    "                results_dict_df[stock].loc[nstate, \"BIC\"]=model.bic(insample_data)\n",
    "            except ValueError:\n",
    "                pass\n",
    "        else: \n",
    "            print(\">\"*10,f\"{stock} {nstate} did not converge\")\n",
    "            results_dict_df[stock].loc[nstate, \"BIC\"]=np.inf\n",
    "            results_dict_df[stock].loc[nstate, \"BIC\"]=np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stock in tickerlist:\n",
    "    columns = [f'{stock}_log_rets', f'{stock}_gk_vol']\n",
    "    insample_data = df[columns]\n",
    "    \n",
    "    best_aic_nstate=results_dict_df[stock][\"AIC\"].astype(float).idxmin()\n",
    "    best_bic_nstate=results_dict_df[stock][\"BIC\"].astype(float).idxmin()\n",
    "    print(f\"For stock {stock}, best AIC: {best_aic_nstate} best BIC: {best_bic_nstate}\")\n",
    "\n",
    "    aic_best_model[stock]=hmm.GaussianHMM(n_components = best_aic_nstate, **param_dict).fit(insample_data)\n",
    "    bic_best_model[stock]=hmm.GaussianHMM(n_components = best_bic_nstate, **param_dict).fit(insample_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating out of sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=f'finaldf_test_{params[\"tablename\"]}.pickle'\n",
    "filename=os.path.join(dataroute, name)\n",
    "with open(filename, 'rb') as handle:\n",
    "    df_test=pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = hmm.GaussianHMM(n_components= 3, **param_dict, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "oos_data=df_test.copy()\n",
    "insample_data=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_date = oos_data.index[0]\n",
    "dates_to_forecast = len(oos_data.index)\n",
    "\n",
    "columns=[\"GGAL_log_rets\",\"GGAL_gk_vol\"]\n",
    "forecasts=pd.DataFrame(columns=columns, index=oos_data.index)\n",
    "\n",
    "oos_data = pd.concat([insample_data, oos_data])\n",
    "del insample_data\n",
    "\n",
    "# vamos a implementar recursive window forecasting\n",
    "\n",
    "index = oos_data.index\n",
    "end_loc = np.where(index >= split_date)[0].min()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2524"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2525"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=1\n",
    "rolling_window=252\n",
    "date_of_first_forecast = oos_data.index[end_loc + i -1]\n",
    "\n",
    "fitstart = end_loc - rolling_window + i\n",
    "fitend = end_loc + i\n",
    "fitend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(252, 39)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oos_data.iloc[fitstart:fitend].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'viterbi',\n",
       " 'covariance_type': 'diag',\n",
       " 'covars_prior': 0.01,\n",
       " 'covars_weight': 1,\n",
       " 'implementation': 'log',\n",
       " 'init_params': 'stmc',\n",
       " 'means_prior': 0,\n",
       " 'means_weight': 0,\n",
       " 'min_covar': 0.001,\n",
       " 'n_components': 3,\n",
       " 'n_iter': 500,\n",
       " 'params': 'stmc',\n",
       " 'random_state': 42,\n",
       " 'startprob_prior': 1.0,\n",
       " 'tol': 0.01,\n",
       " 'transmat_prior': 1.0,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['^MERV_rets', '^MERV_log_rets', '^MERV_gk_vol', 'GGAL.BA_rets',\n",
       "       'GGAL.BA_log_rets', 'GGAL.BA_gk_vol', 'GGAL_rets', 'GGAL_log_rets',\n",
       "       'GGAL_gk_vol', 'YPFD.BA_rets', 'YPFD.BA_log_rets', 'YPFD.BA_gk_vol',\n",
       "       'YPF_rets', 'YPF_log_rets', 'YPF_gk_vol', 'EDN.BA_rets',\n",
       "       'EDN.BA_log_rets', 'EDN.BA_gk_vol', 'EDN_rets', 'EDN_log_rets',\n",
       "       'EDN_gk_vol', 'BMA.BA_rets', 'BMA.BA_log_rets', 'BMA.BA_gk_vol',\n",
       "       'BMA_rets', 'BMA_log_rets', 'BMA_gk_vol', 'BBAR.BA_rets',\n",
       "       'BBAR.BA_log_rets', 'BBAR.BA_gk_vol', 'BBAR_rets', 'BBAR_log_rets',\n",
       "       'BBAR_gk_vol', 'USD_rets', 'USD_log_rets', 'USD_gk_vol',\n",
       "       'USD_^MERV_rets', 'USD_^MERV_log_rets', 'USD_^MERV_gk_vol'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Even though the 'startprob_' attribute is set, it will be overwritten during initialization because 'init_params' contains 's'\n",
      "Even though the 'transmat_' attribute is set, it will be overwritten during initialization because 'init_params' contains 't'\n",
      "Even though the 'means_' attribute is set, it will be overwritten during initialization because 'init_params' contains 'm'\n",
      "Even though the 'covars_' attribute is set, it will be overwritten during initialization because 'init_params' contains 'c'\n"
     ]
    }
   ],
   "source": [
    "fit_data=oos_data.iloc[fitstart:fitend][columns]\n",
    "res=model.fit(fit_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.97645064e-01, 8.02354936e-01, 2.70813830e-85])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.predict_proba(fit_data)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00415891,  0.00156764],\n",
       "       [-0.00128011,  0.00179141],\n",
       "       [-0.06473003,  0.01143463]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.means_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00020512,  0.00174718])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_values=np.dot(res.predict_proba(fit_data)[-1], model.means_)\n",
    "exp_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2023, 6, 2)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_of_first_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GGAL_log_rets</th>\n",
       "      <th>GGAL_gk_vol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-06-02</th>\n",
       "      <td>-0.000205</td>\n",
       "      <td>0.001747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-05</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-06</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-07</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-08</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           GGAL_log_rets GGAL_gk_vol\n",
       "2023-06-02     -0.000205    0.001747\n",
       "2023-06-05           NaN         NaN\n",
       "2023-06-06           NaN         NaN\n",
       "2023-06-07           NaN         NaN\n",
       "2023-06-08           NaN         NaN\n",
       "...                  ...         ...\n",
       "2023-11-24           NaN         NaN\n",
       "2023-11-27           NaN         NaN\n",
       "2023-11-28           NaN         NaN\n",
       "2023-11-29           NaN         NaN\n",
       "2023-11-30           NaN         NaN\n",
       "\n",
       "[123 rows x 2 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecasts.loc[date_of_first_forecast]=exp_values\n",
    "forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.n_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_HMM_samples_residuals_2(model, insample_data, oos_data, columns):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        model (_type_): _description_\n",
    "        insample_data (_type_): _description_\n",
    "        oos_data (_type_): _description_\n",
    "    \"\"\"\n",
    "    # pseudocodigo\n",
    "    # agarra el mejor modelo (esto con una cantidad optima de params ya esta)\n",
    "    # fittear t-j con t-j-252d\n",
    "    # Darle un año de datos hasta t-j para que me prediga la secuencia (probabilidad) de estados.\n",
    "        # Le pido que me prediga las probabilidades de cada estado durante el periodo t-j, t-j-252: \n",
    "        # esto me da una matriz de (252 x n estados)\n",
    "        # esto entiendo es https://hmmlearn.readthedocs.io/en/latest/api.html#hmmlearn.hmm.GaussianHMM.predict_proba\n",
    "    # Tomo la ultima fila de la matriz\n",
    "    # Multiplico esa por el vector de medias estimadas: este punto es mi forecast. \n",
    "        # esto es model.means_ (!)    \n",
    "    \n",
    "    split_date = oos_data.index[0]\n",
    "    dates_to_forecast = len(oos_data.index)\n",
    "\n",
    "    probabilities=pd.DataFrame(columns=oos_data.columns, index=oos_data.index)\n",
    "    forecasts=pd.DataFrame(columns=oos_data.columns, index=oos_data.index)\n",
    "\n",
    "\n",
    "    oos_data = pd.concat([insample_data, oos_data])\n",
    "    del insample_data\n",
    "\n",
    "    # vamos a implementar recursive window forecasting\n",
    "    \n",
    "    index = oos_data.index\n",
    "    end_loc = np.where(index >= split_date)[0].min()\n",
    "    # esto es un int del iloc\n",
    "    # preciso usar ints de iloc porque el timedelta se me va a romper con el fin de semana\n",
    "    rolling_window = 252\n",
    "\n",
    "    nstate=model.n_components\n",
    "    model = hmm.GaussianHMM(n_components = nstate, **param_dict, verbose=False)\n",
    "\n",
    "    for i in range(1, dates_to_forecast):\n",
    "        date_of_first_forecast = oos_data.index[end_loc + i -1]\n",
    "        \n",
    "        fitstart = end_loc - rolling_window + i\n",
    "        fitend = end_loc + i\n",
    "\n",
    "        # fit model with last year\n",
    "        fit_data=oos_data.iloc[fitstart:fitend][columns]\n",
    "        res=model.fit(fit_data)\n",
    "        # TODO: que pasa si fittea mal?\n",
    "        \n",
    "        # obtenemos las probabilidades por estado del ultimo dia\n",
    "        # son las probabilidades que maximizan la log/likelihood de toda la secuencia\n",
    "        last_day_state_probs = res.predict_proba(fit_data)[-1]\n",
    "        probabilities.loc[date_of_first_forecast] = last_day_state_probs\n",
    "\n",
    "        # model.means_ es es la media condicional a cada estado\n",
    "            # cada columna representa cada columna del dataset\n",
    "            # cada fila es un estado\n",
    "        # el producto punto entre este y las probabilidades del ultimo día me da la media esperada por cada columna\n",
    "        expected_means = np.dot(last_day_state_probs, model.means_)\n",
    "        forecasts.loc[date_of_first_forecast]=expected_means\n",
    "        \n",
    "    return probabilities, forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_HMM_samples_residuals(model, insample_data, oos_data):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    # como el modelo es memoryless, sólo necesito 1 día de observación para saber en qué estado estoy\n",
    "    # por lo tanto, en vez de complicarme con dos datasets, puedo agregarle el ultimo día de insample_data al ppio de oos_data\n",
    "    # pseudocodigo\n",
    "    oos_data=pd.concat([insample_data[-1:], oos_data])\n",
    "    del insample_data\n",
    "\n",
    "    samples=pd.DataFrame(columns=oos_data.columns)\n",
    "    residuals=pd.DataFrame(columns=oos_data.columns)\n",
    "\n",
    "    # for i=0\n",
    "    for i in range(1,\n",
    "                   len(oos_data.index)):\n",
    "        prev_obs=oos_data[i-1:i]\n",
    "\n",
    "        todays_obs = oos_data[i:i+1]\n",
    "        todays_date = todays_obs.index\n",
    "\n",
    "        state=model.decode(prev_obs)[1][-1]\n",
    "        # decode()[0] is the log probability, decode()[1] is the sequence of states, [-1] is the last state\n",
    "        # since we have added the last datum of insample_data to oos_data, then the \n",
    "            # TODO: revisar que tenga sentido decodear solo el ultimo día.\n",
    "            # La alternativa es agregar diez días de insample al principio y usar un decode con diez dias, \n",
    "            # me quedo con el ultimo valor del array que maximiza la log-likelihood de la secuencia entera\n",
    "            # pero como es memoryless, not sure if it makesense\n",
    "        \n",
    "        sample = model.sample(n_samples=1, random_state=random_state, currstate=state)[0]\n",
    "        # sample()[0] is the array with observations of the sampled variables, sample()[1] is the value of the currstate\n",
    "        sample = pd.DataFrame(data=sample, columns=oos_data.columns, index=todays_date)\n",
    "\n",
    "        samples=pd.concat([samples, sample])   \n",
    "        # sampling given state t-1\n",
    "        # observar realización en t+i\n",
    "        residual = todays_obs-sample\n",
    "        \n",
    "        residuals=pd.concat([residuals, residual])\n",
    "    \n",
    "    return samples, residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "aic_best_residuals={stock:None for stock in tickerlist}\n",
    "bic_best_residuals={stock:None for stock in tickerlist}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stock in tickerlist:\n",
    "    columns = [f'{stock}_log_rets', f'{stock}_gk_vol']\n",
    "    insample_data = df[columns]\n",
    "    oos_data=df_test[columns]\n",
    "\n",
    "    samples, aic_best_residuals[stock] = generate_HMM_samples_residuals(\n",
    "        aic_best_model[stock], \n",
    "        insample_data=insample_data, \n",
    "        oos_data=oos_data)\n",
    "\n",
    "    samples, bic_best_residuals[stock] = generate_HMM_samples_residuals(\n",
    "        bic_best_model[stock], \n",
    "        insample_data=insample_data, \n",
    "        oos_data=oos_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guardado de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(resultsroute, f\"\"\"HMM_univ_{params[\"tablename\"]}_aic_bestmodels.pickle\"\"\"), \"wb\") as output_file:\n",
    "    pickle.dump(aic_best_model, output_file)\n",
    "\n",
    "with open(os.path.join(resultsroute, f\"\"\"HMM_univ_{params[\"tablename\"]}_bic_bestmodels.pickle\"\"\"), \"wb\") as output_file:\n",
    "    pickle.dump(bic_best_model, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(resultsroute, f\"\"\"HMM_univ_{params[\"tablename\"]}_aic_residuals.pickle\"\"\"), \"wb\") as output_file:\n",
    "    pickle.dump(aic_best_residuals, output_file)\n",
    "\n",
    "with open(os.path.join(resultsroute, f\"\"\"HMM_univ_{params[\"tablename\"]}_bic_residuals.pickle\"\"\"), \"wb\") as output_file:\n",
    "    pickle.dump(bic_best_residuals, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graficando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_close_rets_vol(model, data, key, IC):\n",
    "    prediction= model.predict(data)\n",
    "    states=set(prediction)\n",
    "\n",
    "    fig=plt.figure(figsize = (20, 20))\n",
    "    plt.tight_layout()\n",
    "    plt.title(f\"{key} Log returns and intraday Vol\\n{model.n_components} states / best by {IC}\")\n",
    "\n",
    "    for subplot, var in zip(range(1,3), data.columns):    \n",
    "        plt.subplot(2,1,subplot)\n",
    "        for i in set(prediction):\n",
    "            state = (prediction == i)\n",
    "            x = data.index[state]\n",
    "            y = data[var].iloc[state]\n",
    "            plt.plot(x, y, '.')\n",
    "        plt.legend(states, fontsize=16)\n",
    "        \n",
    "        plt.grid(True)\n",
    "        plt.xlabel(\"datetime\", fontsize=16)\n",
    "        plt.ylabel(var, fontsize=16)\n",
    "            \n",
    "    plt.savefig(os.path.join(resultsroute, \"graphs\", \n",
    "                             f\"HMM\", \n",
    "                             f\"{key}_model_{IC}.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for dictionary, IC in zip([aic_best_model, bic_best_model], [\"AIC\", \"BIC\"]):\n",
    "    for key, model in dictionary.items():\n",
    "        columns = [f'{stock}_log_rets', f'{stock}_gk_vol']\n",
    "        insample_data = df[columns]\n",
    "        oos_data=df_test[columns]\n",
    "        train_end=insample_data.index.max()\n",
    "        data=pd.concat([insample_data, oos_data])\n",
    "\n",
    "        plot_close_rets_vol(model, data, key, IC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HMM Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting the Number of States in Hidden Markov Models: Pragmatic Solutions Illustrated Using Animal Movement\n",
    "https://sci-hub.st/10.1007/s13253-017-0283-8"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
