{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codigo reciclado\n",
    "Tiene sentido revisar todo esto? Por lo menos en esta instancia me parece que NO, salvo que me lo pidan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology:\n",
    "Quiero contestar:  \n",
    "* Hay autocorrelacion clusterizada de la varianza? Puedo verlo:\n",
    "    * Graficamente ACF y PACF\n",
    "    * Por tests ACF y PACF\n",
    "* Hay no normalidad? \n",
    "    * como se comporta en las colas?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Startup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroute=os.path.join(\"..\",  \"data\")\n",
    "resultsroute=os.path.join(\"..\",  \"results\", \"descriptive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "start='2013-01-01'\n",
    "end=\"2023-06-01\"\n",
    "\n",
    "name=f'processed_dataset_{start}_{end}.pickle'\n",
    "filename=os.path.join(dataroute, name)\n",
    "\n",
    "with open(filename, 'rb') as handle:\n",
    "    data=pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.set_style(style='darkgrid')\n",
    "sb.set_palette(sb.color_palette(palette='deep'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_vol(data, name):\n",
    "    data[name]['gk_vol'].plot(ax=ax1)\n",
    "    ax1.grid(True)\n",
    "    ax1.set_xlabel('Time')\n",
    "    ax1.set_ylabel('Variance')\n",
    "    ax1.set_title(f'Garman-Klass intraday Volatility for {name}')\n",
    "    fig.savefig(route_graphs + f'{name}_variance.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_datareader as web\n",
    "\n",
    "import scipy.stats as scs\n",
    "from scipy.stats import norm\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "\n",
    "import datetime as dt\n",
    "import seaborn as sb\n",
    "\n",
    "return_lists = ['Returns', 'Log Returns', 'Abs Returns', 'Sqr Returns']\n",
    "\n",
    "\n",
    "def autocorrelograms(df, names, lags):\n",
    "    \"\"\"\n",
    "    :param df: diccionario con dataframes adentro\n",
    "    :param list: lista con los #n nombres de las acciones que vamos a calcular\n",
    "    :return:guarda #n graficos de autocorrelacion en la ruta seleccionada\n",
    "    \"\"\"\n",
    "    for name in names:\n",
    "        fig = plt.figure(figsize=[13.6, 10.2])\n",
    "        ax1 = fig.add_subplot(3, 1, 1)\n",
    "        ax2 = fig.add_subplot(3, 1, 2, sharex=ax1)\n",
    "        ax3 = fig.add_subplot(3, 1, 3, sharex=ax1)\n",
    "\n",
    "        plot_acf(df[name]['Log Returns'],\n",
    "                 lags=lags,                 # Cuantos lags busco autocorrelacionar\n",
    "                 zero=False,                # Si tomo el lag cero\n",
    "                 alpha=0.05,                # El rango de certeza marcado en azul\n",
    "                 use_vlines=False,          # Lineas verticales que conectan cada punto con el eje x\n",
    "                 ax=ax1)                    # La posicion en la figura\n",
    "        ax1.grid(True)\n",
    "        ax1.set_xlabel('Lag')\n",
    "        ax1.set_ylabel('Autocorrelation')\n",
    "        ax1.set_title(f'Autocorrelation of Log returns for {name}')\n",
    "\n",
    "        plot_acf(df[name]['Abs Returns'],\n",
    "                 lags=lags,                 # Cuantos lags busco autocorrelacionar\n",
    "                 zero=False,                # Si tomo el lag cero\n",
    "                 alpha=0.05,                # El rango de certeza marcado en azul\n",
    "                 use_vlines=False,          # Lineas verticales que conectan cada punto con el eje x\n",
    "                 ax=ax2)                    # La posicion en la figura\n",
    "        ax2.grid(True)\n",
    "        ax2.set_xlabel('Lag')\n",
    "        ax2.set_ylabel('Autocorrelation')\n",
    "        ax2.set_title(f'Autocorrelation of Abs returns for {name}')\n",
    "\n",
    "        plot_acf(df[name]['Sqr Returns'],\n",
    "                 lags=lags,                 # Cuantos lags busco autocorrelacionar\n",
    "                 zero=False,                # Si tomo el lag cero\n",
    "                 alpha=0.05,                # El rango de certeza marcado en azul\n",
    "                 use_vlines=False,          # Lineas verticales que conectan cada punto con el eje x\n",
    "                 ax=ax3)                    # La posicion en la figura\n",
    "        ax3.grid(True)\n",
    "        ax3.set_xlabel('Lag')\n",
    "        ax3.set_ylabel('Autocorrelation')\n",
    "        ax3.set_title(f'Autocorrelation of Sqr returns for {name}')\n",
    "\n",
    "        fig.savefig(route_graphs + f'{name}_autocorrs_returns.png')\n",
    "\n",
    "# autocorrelograms(dfs, stocks, 252)\n",
    "\n",
    "def ac_test(df, names, lags):\n",
    "    \"FINALMENTE NO USE ESTA FUNCION\"\n",
    "    ac_list = []\n",
    "    ac_pvals = []\n",
    "    pac_list = []\n",
    "\n",
    "    for rets in return_lists:\n",
    "        for name in names:\n",
    "            ac, confint, qstat, pvals = acf(df[name][rets],nlags=lags, qstat=True, alpha=0.05)\n",
    "            ac_list.append(np.round(ac[:5],3))\n",
    "            ac_pvals.append(pvals[:5])\n",
    "\n",
    "        ac_df = pd.DataFrame(ac_list)\n",
    "        ac_df.index = names\n",
    "        ac_df.to_csv(route_tables + f'{rets}_ac_table.csv')\n",
    "\n",
    "        ac_p_df = pd.DataFrame(np.round(ac_pvals,3))\n",
    "        ac_p_df.index = names\n",
    "        ac_p_df.to_csv(route_tables + f'{rets}_ac_pval_table.csv')\n",
    "\n",
    "        ac_list = []\n",
    "        ac_pvals = []\n",
    "\n",
    "    return ac_df, ac_p_df\n",
    "\n",
    "# ac_test(dfs, stocks, 252)\n",
    "\n",
    "def pac_test(df, names, lags):\n",
    "    \"FINALMENTE NO USE ESTA FUNCION\"\n",
    "    pac_list = []\n",
    "\n",
    "    for rets in return_lists:\n",
    "        for name in names:\n",
    "            pac = pacf(df[name][rets], nlags=lags)\n",
    "            pac_list.append(np.round(pac[:5], 3))\n",
    "\n",
    "        pac_df = pd.DataFrame(pac_list)\n",
    "        pac_df.index = names\n",
    "        pac_df.to_csv(route_tables + f'{rets}_pac_table.csv')\n",
    "\n",
    "        pac_list=[]\n",
    "\n",
    "    return pac_df\n",
    "\n",
    "# pac_test(dfs, stocks, 252)\n",
    "\n",
    "\n",
    "def partial_autocorrelograms(df, names, lags):\n",
    "    \"\"\"\n",
    "\n",
    "    :param df: diccionario con dataframes adentro\n",
    "    :param list: lista con los #n nombres de las acciones que vamos a calcular\n",
    "    :return:guarda #n graficos de autocorrelacion en la ruta seleccionada\n",
    "    \"\"\"\n",
    "    for name in names:\n",
    "        fig = plt.figure(figsize=[13.6, 10.2])\n",
    "        ax1 = fig.add_subplot(3, 1, 1)\n",
    "        ax2 = fig.add_subplot(3, 1, 2, sharex=ax1)\n",
    "        ax3 = fig.add_subplot(3, 1, 3, sharex=ax1)\n",
    "\n",
    "        plot_pacf(df[name]['Log Returns'],\n",
    "                  method='ywunbiased',          # Metodo de Yule Walker con correccion de sesgo por autocovarianzas\n",
    "                  lags=lags,                    # Cuantos lags busco autocorrelacionar\n",
    "                  zero=False,                   # Si tomo el lag cero\n",
    "                  alpha=0.05,                   # El rango de certeza marcado en azul\n",
    "                  use_vlines=False,             # Lineas verticales que conectan cada punto con el eje x\n",
    "                  ax=ax1)                       # La posicion en la figura\n",
    "        ax1.grid(True)\n",
    "        ax1.set_xlabel('Lag')\n",
    "        ax1.set_ylabel('Partial Autocorrelation')\n",
    "        ax1.set_title(f'Partial Autocorrelation of Log returns for {name}')\n",
    "\n",
    "        plot_pacf(df[name]['Abs Returns'],\n",
    "                  method='ywunbiased',          # Metodo de Yule Walker con correccion de sesgo por autocovarianzas\n",
    "                  lags=lags,                    # Cuantos lags busco autocorrelacionar\n",
    "                  zero=False,                   # Si tomo el lag cero\n",
    "                  alpha=0.05,                   # El rango de certeza marcado en azul\n",
    "                  use_vlines=False,             # Lineas verticales que conectan cada punto con el eje x\n",
    "                  ax=ax2)                       # La posicion en la figura\n",
    "        ax2.grid(True)\n",
    "        ax2.set_xlabel('Lag')\n",
    "        ax2.set_ylabel('Partial Autocorrelation')\n",
    "        ax2.set_title(f'Partial Autocorrelation of Abs returns for {name}')\n",
    "        \n",
    "        plot_pacf(df[name]['Sqr Returns'],\n",
    "                  method='ywunbiased',          # Metodo de Yule Walker con correccion de sesgo por autocovarianzas\n",
    "                  lags=lags,                    # Cuantos lags busco autocorrelacionar\n",
    "                  zero=False,                   # Si tomo el lag cero\n",
    "                  alpha=0.05,                   # El rango de certeza marcado en azul\n",
    "                  use_vlines=False,             # Lineas verticales que conectan cada punto con el eje x\n",
    "                  ax=ax3)                       # La posicion en la figura\n",
    "        ax3.grid(True)\n",
    "        ax3.set_xlabel('Lag')\n",
    "        ax3.set_ylabel('Partial Autocorrelation')\n",
    "        ax3.set_title(f'Partial Autocorrelation of Sqr returns for {name}')\n",
    "        \n",
    "        fig.savefig(route_graphs + f'{name}_partial_autocorrs_returns.png')\n",
    "\n",
    "# partial_autocorrelograms(dfs,stocks,252)\n",
    "\n",
    "def histograms(df, names):\n",
    "    for name in names:\n",
    "        fig = plt.figure(figsize=[13.6, 10.2])\n",
    "        ax1 = fig.add_subplot(3, 1, 1)\n",
    "        ax2 = fig.add_subplot(3, 1, 2)\n",
    "        ax3 = fig.add_subplot(3, 1, 3)\n",
    "\n",
    "        sb.distplot(df[name]['Log Returns'].fillna(0),\n",
    "                    ax=ax1,\n",
    "                    hist=True,\n",
    "                    bins=int(np.ceil(np.log2(len(df[name])) + 15)),\n",
    "                    label='Datos observados',\n",
    "                    kde=True,\n",
    "                    kde_kws={\"color\":\"k\", \"lw\":2, \"label\":\"KDE\"},\n",
    "                    fit=norm,\n",
    "                    fit_kws = {\"color\":\"r\", \"lw\":3, \"label\":\"Normal Teorica\"})\n",
    "        # TODO: No me esta dando que las frecuencias relativas esten ni cerca de lo esperable\n",
    "        plt.grid(True)\n",
    "        plt.xlabel('Log Returns')\n",
    "        plt.ylabel('Frequency')\n",
    "        #plt.legend(True)\n",
    "        plt.title(f'Histogram for Log returns frequency for {name}')\n",
    "\n",
    "        sb.distplot(df[name]['Abs Returns'].fillna(0),\n",
    "                    ax=ax2,\n",
    "                    hist=True,\n",
    "                    bins=int(np.ceil(np.log2(len(df[name])) + 15)),\n",
    "                    label='Datos observados')\n",
    "                    # SAQUE LO DE ABAJO PQ FLASHIE\n",
    "                    # kde=True,\n",
    "                    # kde_kws={\"color\":\"k\", \"lw\":2, \"label\":\"KDE\"},\n",
    "                    # fit=halfnorm,\n",
    "                    # fit_kws = {\"color\":\"r\", \"lw\":3, \"label\":\"Media Normal Teorica\"})\n",
    "\n",
    "        plt.grid(True)\n",
    "        plt.xlabel('Abs Returns')\n",
    "        plt.ylabel('Frequency')\n",
    "        #plt.legend(True)\n",
    "        plt.title(f'Histogram for Abs Returns frequency for {name}')\n",
    "\n",
    "        sb.distplot(df[name]['Sqr Returns'].fillna(0),\n",
    "                    ax=ax3,\n",
    "                    hist=True,\n",
    "                    bins=int(np.ceil(np.log2(len(df[name])) + 15)),\n",
    "                    label='Datos observados')\n",
    "                    # kde=True,\n",
    "                    # kde_kws={\"color\":\"k\", \"lw\":2, \"label\":\"KDE\"},\n",
    "                    # fit=chi2,\n",
    "                    # fit_kws = {\"color\":\"r\", \"lw\":3, \"label\":\"Chi Cuadrada Teorica\"})\n",
    "\n",
    "        plt.grid(True)\n",
    "        plt.xlabel('Sqr Returns')\n",
    "        plt.ylabel('Frequency')\n",
    "        #plt.legend(True)\n",
    "        plt.title(f'Histogram for Sqr Returns frequency for {name}')\n",
    "\n",
    "        fig.savefig(route_graphs + f'{name}_histogram_returns.png')\n",
    "\n",
    "# histograms(dfs, stocks)\n",
    "def histogram_normal(df, names):\n",
    "    for name in names:\n",
    "        fig = plt.figure(figsize=[13.6, 5.1])\n",
    "        ax1 = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "        sb.distplot(df[name]['Returns'].fillna(0),\n",
    "                    ax=ax1,\n",
    "                    hist=True,\n",
    "                    bins=int(np.ceil(np.log2(len(df[name])) + 15)),\n",
    "                    label='Datos observados',\n",
    "                    fit=norm,\n",
    "                    fit_kws = {\"color\":\"r\", \"lw\":3, \"label\":\"Normal Teorica\"})\n",
    "\n",
    "        plt.grid(True)\n",
    "        plt.xlabel('Log Returns')\n",
    "        plt.ylabel('Frequency')\n",
    "        #plt.legend(True)\n",
    "        plt.title(f'Histogram for simple return frequency for {name}')\n",
    "        fig.savefig(route_graphs + f'{name}_normality_histogram_returns.png')\n",
    "\n",
    "# histogram_normal(dfs, stocks)\n",
    "\n",
    "def normality_test(arr):\n",
    "    arr = arr.fillna(0)\n",
    "    print('Skewness coefficient: ' + str(np.round(scs.skew(arr), 2)))\n",
    "    print('Skewness test p-value: ' + str(1 - np.round(scs.skewtest(arr)[1], 2)))\n",
    "    print('Kurtosis coefficient: ' + str(np.round(scs.kurtosis(arr), 2)))\n",
    "    print('Kurtosis test p-value: ' + str(1 - np.round(scs.kurtosistest(arr)[1], 2)))\n",
    "    print('Normality test p-value: ' + str(1 - np.round(scs.normaltest(arr)[1], 2)))\n",
    "\n",
    "def normality_table(df, names, values):\n",
    "    \"\"\"\n",
    "    :param df: \n",
    "    :param names: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    skew = []\n",
    "    skew_pval = []\n",
    "    kurt = []\n",
    "    kurt_pval = []\n",
    "    norm_pval = []\n",
    "\n",
    "    for name in names:\n",
    "        skew.append(np.round(scs.skew(df[name][values]), 3))\n",
    "        skew_pval.append(np.round(scs.skewtest(df[name][values])[1], 3))\n",
    "        kurt.append(np.round(scs.kurtosis(df[name][values]), 3))\n",
    "        kurt_pval.append(np.round(scs.kurtosistest(df[name][values])[1], 3))\n",
    "        norm_pval.append(np.round(scs.normaltest(df[name][values])[1], 3))\n",
    "\n",
    "    dictionary = {'Skewness':skew, 'Skew p-value':skew_pval, 'Kurtosis':kurt, 'Kurtosis p-value':kurt_pval,\n",
    "                  'Normality test p-value':norm_pval}\n",
    "\n",
    "    table = pd.DataFrame(dictionary)\n",
    "    table.index = names\n",
    "    table.to_csv(route_tables+f'norm_table_{values}.csv')\n",
    "\n",
    "    return table\n",
    "\n",
    "# for rets in return_lists:\n",
    "#     normality_table(dfs, stocks, rets)\n",
    "\n",
    "\n",
    "def describe_and_test_norm(df, names, values):\n",
    "    \"FINALMENTE NO USÃˆ ESTA FUNICON\"\n",
    "    for name in names:\n",
    "        print(values + ' tests for ' + name)\n",
    "        print(df[name][values].describe())\n",
    "        print('')\n",
    "        print(values+' tests for '+name)\n",
    "        normality_test(df[name][values])\n",
    "        print('')\n",
    "        print('-' * 10)\n",
    "\n",
    "    table = normality_table(df, names, values)\n",
    "\n",
    "    return table\n",
    "            \n",
    "\n",
    "# describe_and_test_norm(dfs, stocks, 'Returns')\n",
    "\n",
    "\n",
    "\"\"\n",
    "\n",
    "## para tests de residuales\n",
    "def residuals_test_plot(residual, lags, alpha_graph=0.05,**kwargs):\n",
    "    \"\"\"\n",
    "    TODO: FUNCION SIN USO AUN.\n",
    "    :param residual: The model Residual we want to test\n",
    "    :param lags: the amount of lags we want to run the ACF/PACF on and the lags on the Ljung-Box test\n",
    "    :param alpha_graph: The significance of the graph region\n",
    "    :param name: Name for the graph\n",
    "    :return: the p-value tuple and a saved ACF/PACF graph\n",
    "    \"\"\"\n",
    "    fig = plt.Figure(figsize=[10.2, 13.6])\n",
    "    ax1 = fig.add_subplot(2, 1, 1)\n",
    "    ax2 = fig.add_subplot(2, 1, 2)\n",
    "\n",
    "    plot_acf(residual, lags=lags, zero=False, alpha=alpha_graph, ax=ax1)\n",
    "    plot_pacf(residual, lags=lags, zero=False, alpha=alpha_graph, ax=ax2)\n",
    "    plt.show()\n",
    "\n",
    "    name = kwargs.get('name', 'model')\n",
    "    fig.savefig(f'{name}_ACF_PACF')\n",
    "\n",
    "    test = acorr_ljungbox(residual, lags=lags)\n",
    "\n",
    "    print('The p-values for the residuals are:')\n",
    "    print(test[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
