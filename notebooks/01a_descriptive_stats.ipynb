{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Startup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_datareader as web\n",
    "\n",
    "import scipy.stats as scs\n",
    "from scipy.stats import norm\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "\n",
    "import datetime as dt\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.params import get_params\n",
    "\n",
    "params = get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroute = os.path.join(\"..\", \"data\")\n",
    "processedroute = os.path.join(\"...\", \"processed\")\n",
    "resultsroute = os.path.join(\"..\", \"results\")\n",
    "descriptivegraphsroute=os.path.join(resultsroute, \"graphs\", \"descriptive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = f'finaldf_train_{params[\"tablename\"]}.pickle'\n",
    "filename = os.path.join(dataroute, name)\n",
    "with open(filename, \"rb\") as handle:\n",
    "    df = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>^MERV_rets</th>\n",
       "      <th>^MERV_log_rets</th>\n",
       "      <th>^MERV_gk_vol</th>\n",
       "      <th>GGAL.BA_rets</th>\n",
       "      <th>GGAL.BA_log_rets</th>\n",
       "      <th>GGAL.BA_gk_vol</th>\n",
       "      <th>GGAL_rets</th>\n",
       "      <th>GGAL_log_rets</th>\n",
       "      <th>GGAL_gk_vol</th>\n",
       "      <th>YPFD.BA_rets</th>\n",
       "      <th>...</th>\n",
       "      <th>BBAR.BA_gk_vol</th>\n",
       "      <th>BBAR_rets</th>\n",
       "      <th>BBAR_log_rets</th>\n",
       "      <th>BBAR_gk_vol</th>\n",
       "      <th>USD_rets</th>\n",
       "      <th>USD_log_rets</th>\n",
       "      <th>USD_gk_vol</th>\n",
       "      <th>USD_^MERV_rets</th>\n",
       "      <th>USD_^MERV_log_rets</th>\n",
       "      <th>USD_^MERV_gk_vol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>0.007552</td>\n",
       "      <td>0.007524</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.010616</td>\n",
       "      <td>0.010560</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>-0.012748</td>\n",
       "      <td>-0.012830</td>\n",
       "      <td>0.001228</td>\n",
       "      <td>-0.006862</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>-0.005725</td>\n",
       "      <td>-0.005742</td>\n",
       "      <td>0.000960</td>\n",
       "      <td>0.008830</td>\n",
       "      <td>0.008792</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.001247</td>\n",
       "      <td>0.001246</td>\n",
       "      <td>0.000129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>0.007092</td>\n",
       "      <td>0.007067</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>-0.006303</td>\n",
       "      <td>-0.006323</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>-0.010043</td>\n",
       "      <td>-0.010094</td>\n",
       "      <td>0.000554</td>\n",
       "      <td>0.004936</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>-0.019194</td>\n",
       "      <td>-0.019381</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>0.018043</td>\n",
       "      <td>0.017883</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>-0.005727</td>\n",
       "      <td>-0.005744</td>\n",
       "      <td>0.000158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-07</th>\n",
       "      <td>-0.001035</td>\n",
       "      <td>-0.001035</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.002114</td>\n",
       "      <td>0.002112</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>-0.014493</td>\n",
       "      <td>-0.014599</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.010805</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>0.015656</td>\n",
       "      <td>0.015534</td>\n",
       "      <td>0.000511</td>\n",
       "      <td>-0.002489</td>\n",
       "      <td>-0.002492</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>-0.009769</td>\n",
       "      <td>-0.009817</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-08</th>\n",
       "      <td>0.008285</td>\n",
       "      <td>0.008251</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>-0.008439</td>\n",
       "      <td>-0.008475</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>-0.016176</td>\n",
       "      <td>-0.016309</td>\n",
       "      <td>0.001085</td>\n",
       "      <td>0.049563</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>-0.015414</td>\n",
       "      <td>-0.015534</td>\n",
       "      <td>0.000642</td>\n",
       "      <td>0.015356</td>\n",
       "      <td>0.015239</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>-0.001117</td>\n",
       "      <td>-0.001118</td>\n",
       "      <td>0.000082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-09</th>\n",
       "      <td>0.017826</td>\n",
       "      <td>0.017669</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011958</td>\n",
       "      <td>0.011887</td>\n",
       "      <td>0.005238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.003914</td>\n",
       "      <td>-0.003921</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>-0.008671</td>\n",
       "      <td>-0.008709</td>\n",
       "      <td>0.001065</td>\n",
       "      <td>0.017245</td>\n",
       "      <td>0.017098</td>\n",
       "      <td>0.000273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ^MERV_rets  ^MERV_log_rets  ^MERV_gk_vol  GGAL.BA_rets  \\\n",
       "2013-01-03    0.007552        0.007524      0.000129      0.010616   \n",
       "2013-01-04    0.007092        0.007067      0.000158     -0.006303   \n",
       "2013-01-07   -0.001035       -0.001035      0.000022      0.002114   \n",
       "2013-01-08    0.008285        0.008251      0.000082     -0.008439   \n",
       "2013-01-09    0.017826        0.017669      0.000273      0.000000   \n",
       "\n",
       "            GGAL.BA_log_rets  GGAL.BA_gk_vol  GGAL_rets  GGAL_log_rets  \\\n",
       "2013-01-03          0.010560        0.000677  -0.012748      -0.012830   \n",
       "2013-01-04         -0.006323        0.000208  -0.010043      -0.010094   \n",
       "2013-01-07          0.002112        0.000063  -0.014493      -0.014599   \n",
       "2013-01-08         -0.008475        0.000153  -0.016176      -0.016309   \n",
       "2013-01-09          0.000000        0.000000   0.011958       0.011887   \n",
       "\n",
       "            GGAL_gk_vol  YPFD.BA_rets  ...  BBAR.BA_gk_vol  BBAR_rets  \\\n",
       "2013-01-03     0.001228     -0.006862  ...        0.000169  -0.005725   \n",
       "2013-01-04     0.000554      0.004936  ...        0.000406  -0.019194   \n",
       "2013-01-07     0.000517      0.010805  ...        0.000492   0.015656   \n",
       "2013-01-08     0.001085      0.049563  ...        0.000438  -0.015414   \n",
       "2013-01-09     0.005238      0.000000  ...        0.000000  -0.003914   \n",
       "\n",
       "            BBAR_log_rets  BBAR_gk_vol  USD_rets  USD_log_rets  USD_gk_vol  \\\n",
       "2013-01-03      -0.005742     0.000960  0.008830      0.008792    0.000014   \n",
       "2013-01-04      -0.019381     0.000635  0.018043      0.017883    0.000133   \n",
       "2013-01-07       0.015534     0.000511 -0.002489     -0.002492    0.000048   \n",
       "2013-01-08      -0.015534     0.000642  0.015356      0.015239    0.000064   \n",
       "2013-01-09      -0.003921     0.000147 -0.008671     -0.008709    0.001065   \n",
       "\n",
       "            USD_^MERV_rets  USD_^MERV_log_rets  USD_^MERV_gk_vol  \n",
       "2013-01-03        0.001247            0.001246          0.000129  \n",
       "2013-01-04       -0.005727           -0.005744          0.000158  \n",
       "2013-01-07       -0.009769           -0.009817          0.000022  \n",
       "2013-01-08       -0.001117           -0.001118          0.000082  \n",
       "2013-01-09        0.017245            0.017098          0.000273  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.set_style(style='darkgrid')\n",
    "sb.set_palette(sb.color_palette(palette='deep'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns: \n",
    "    if column.endswith(\"log_rets\"):\n",
    "        fig=df[column].plot(title=column).get_figure()\n",
    "        fig.savefig(os.path.join(descriptivegraphsroute, \"log_rets\", f\"{column}.png\"))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns: \n",
    "    if column.endswith(\"gk_vol\"):\n",
    "        fig=df[column].plot(title=column).get_figure()\n",
    "        fig.savefig(os.path.join(descriptivegraphsroute, \"gk_vol\", f\"{column}.png\"))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocorrelograms(df, names, lags):\n",
    "    \"\"\"\n",
    "    :param df: diccionario con dataframes adentro\n",
    "    :param list: lista con los #n nombres de las acciones que vamos a calcular\n",
    "    :return:guarda #n graficos de autocorrelacion en la ruta seleccionada\n",
    "    \"\"\"\n",
    "    for name in names:\n",
    "        fig = plt.figure(figsize=[13.6, 10.2])\n",
    "        ax1 = fig.add_subplot(3, 1, 1)\n",
    "        ax2 = fig.add_subplot(3, 1, 2, sharex=ax1)\n",
    "        ax3 = fig.add_subplot(3, 1, 3, sharex=ax1)\n",
    "\n",
    "        plot_acf(df[name]['Log Returns'],\n",
    "                 lags=lags,                 # Cuantos lags busco autocorrelacionar\n",
    "                 zero=False,                # Si tomo el lag cero\n",
    "                 alpha=0.05,                # El rango de certeza marcado en azul\n",
    "                 use_vlines=False,          # Lineas verticales que conectan cada punto con el eje x\n",
    "                 ax=ax1)                    # La posicion en la figura\n",
    "        ax1.grid(True)\n",
    "        ax1.set_xlabel('Lag')\n",
    "        ax1.set_ylabel('Autocorrelation')\n",
    "        ax1.set_title(f'Autocorrelation of Log returns for {name}')\n",
    "\n",
    "        plot_acf(df[name]['Abs Returns'],\n",
    "                 lags=lags,                 # Cuantos lags busco autocorrelacionar\n",
    "                 zero=False,                # Si tomo el lag cero\n",
    "                 alpha=0.05,                # El rango de certeza marcado en azul\n",
    "                 use_vlines=False,          # Lineas verticales que conectan cada punto con el eje x\n",
    "                 ax=ax2)                    # La posicion en la figura\n",
    "        ax2.grid(True)\n",
    "        ax2.set_xlabel('Lag')\n",
    "        ax2.set_ylabel('Autocorrelation')\n",
    "        ax2.set_title(f'Autocorrelation of Abs returns for {name}')\n",
    "\n",
    "        plot_acf(df[name]['Sqr Returns'],\n",
    "                 lags=lags,                 # Cuantos lags busco autocorrelacionar\n",
    "                 zero=False,                # Si tomo el lag cero\n",
    "                 alpha=0.05,                # El rango de certeza marcado en azul\n",
    "                 use_vlines=False,          # Lineas verticales que conectan cada punto con el eje x\n",
    "                 ax=ax3)                    # La posicion en la figura\n",
    "        ax3.grid(True)\n",
    "        ax3.set_xlabel('Lag')\n",
    "        ax3.set_ylabel('Autocorrelation')\n",
    "        ax3.set_title(f'Autocorrelation of Sqr returns for {name}')\n",
    "\n",
    "        fig.savefig(route_graphs + f'{name}_autocorrs_returns.png')\n",
    "\n",
    "# autocorrelograms(dfs, stocks, 252)\n",
    "\n",
    "def ac_test(df, names, lags):\n",
    "    \"FINALMENTE NO USE ESTA FUNCION\"\n",
    "    ac_list = []\n",
    "    ac_pvals = []\n",
    "    pac_list = []\n",
    "\n",
    "    for rets in return_lists:\n",
    "        for name in names:\n",
    "            ac, confint, qstat, pvals = acf(df[name][rets],nlags=lags, qstat=True, alpha=0.05)\n",
    "            ac_list.append(np.round(ac[:5],3))\n",
    "            ac_pvals.append(pvals[:5])\n",
    "\n",
    "        ac_df = pd.DataFrame(ac_list)\n",
    "        ac_df.index = names\n",
    "        ac_df.to_csv(route_tables + f'{rets}_ac_table.csv')\n",
    "\n",
    "        ac_p_df = pd.DataFrame(np.round(ac_pvals,3))\n",
    "        ac_p_df.index = names\n",
    "        ac_p_df.to_csv(route_tables + f'{rets}_ac_pval_table.csv')\n",
    "\n",
    "        ac_list = []\n",
    "        ac_pvals = []\n",
    "\n",
    "    return ac_df, ac_p_df\n",
    "\n",
    "# ac_test(dfs, stocks, 252)\n",
    "\n",
    "def pac_test(df, names, lags):\n",
    "    \"FINALMENTE NO USE ESTA FUNCION\"\n",
    "    pac_list = []\n",
    "\n",
    "    for rets in return_lists:\n",
    "        for name in names:\n",
    "            pac = pacf(df[name][rets], nlags=lags)\n",
    "            pac_list.append(np.round(pac[:5], 3))\n",
    "\n",
    "        pac_df = pd.DataFrame(pac_list)\n",
    "        pac_df.index = names\n",
    "        pac_df.to_csv(route_tables + f'{rets}_pac_table.csv')\n",
    "\n",
    "        pac_list=[]\n",
    "\n",
    "    return pac_df\n",
    "\n",
    "# pac_test(dfs, stocks, 252)\n",
    "\n",
    "\n",
    "def partial_autocorrelograms(df, names, lags):\n",
    "    \"\"\"\n",
    "\n",
    "    :param df: diccionario con dataframes adentro\n",
    "    :param list: lista con los #n nombres de las acciones que vamos a calcular\n",
    "    :return:guarda #n graficos de autocorrelacion en la ruta seleccionada\n",
    "    \"\"\"\n",
    "    for name in names:\n",
    "        fig = plt.figure(figsize=[13.6, 10.2])\n",
    "        ax1 = fig.add_subplot(3, 1, 1)\n",
    "        ax2 = fig.add_subplot(3, 1, 2, sharex=ax1)\n",
    "        ax3 = fig.add_subplot(3, 1, 3, sharex=ax1)\n",
    "\n",
    "        plot_pacf(df[name]['Log Returns'],\n",
    "                  method='ywunbiased',          # Metodo de Yule Walker con correccion de sesgo por autocovarianzas\n",
    "                  lags=lags,                    # Cuantos lags busco autocorrelacionar\n",
    "                  zero=False,                   # Si tomo el lag cero\n",
    "                  alpha=0.05,                   # El rango de certeza marcado en azul\n",
    "                  use_vlines=False,             # Lineas verticales que conectan cada punto con el eje x\n",
    "                  ax=ax1)                       # La posicion en la figura\n",
    "        ax1.grid(True)\n",
    "        ax1.set_xlabel('Lag')\n",
    "        ax1.set_ylabel('Partial Autocorrelation')\n",
    "        ax1.set_title(f'Partial Autocorrelation of Log returns for {name}')\n",
    "\n",
    "        plot_pacf(df[name]['Abs Returns'],\n",
    "                  method='ywunbiased',          # Metodo de Yule Walker con correccion de sesgo por autocovarianzas\n",
    "                  lags=lags,                    # Cuantos lags busco autocorrelacionar\n",
    "                  zero=False,                   # Si tomo el lag cero\n",
    "                  alpha=0.05,                   # El rango de certeza marcado en azul\n",
    "                  use_vlines=False,             # Lineas verticales que conectan cada punto con el eje x\n",
    "                  ax=ax2)                       # La posicion en la figura\n",
    "        ax2.grid(True)\n",
    "        ax2.set_xlabel('Lag')\n",
    "        ax2.set_ylabel('Partial Autocorrelation')\n",
    "        ax2.set_title(f'Partial Autocorrelation of Abs returns for {name}')\n",
    "        \n",
    "        plot_pacf(df[name]['Sqr Returns'],\n",
    "                  method='ywunbiased',          # Metodo de Yule Walker con correccion de sesgo por autocovarianzas\n",
    "                  lags=lags,                    # Cuantos lags busco autocorrelacionar\n",
    "                  zero=False,                   # Si tomo el lag cero\n",
    "                  alpha=0.05,                   # El rango de certeza marcado en azul\n",
    "                  use_vlines=False,             # Lineas verticales que conectan cada punto con el eje x\n",
    "                  ax=ax3)                       # La posicion en la figura\n",
    "        ax3.grid(True)\n",
    "        ax3.set_xlabel('Lag')\n",
    "        ax3.set_ylabel('Partial Autocorrelation')\n",
    "        ax3.set_title(f'Partial Autocorrelation of Sqr returns for {name}')\n",
    "        \n",
    "        fig.savefig(route_graphs + f'{name}_partial_autocorrs_returns.png')\n",
    "\n",
    "# partial_autocorrelograms(dfs,stocks,252)\n",
    "\n",
    "def histograms(df, names):\n",
    "    for name in names:\n",
    "        fig = plt.figure(figsize=[13.6, 10.2])\n",
    "        ax1 = fig.add_subplot(3, 1, 1)\n",
    "        ax2 = fig.add_subplot(3, 1, 2)\n",
    "        ax3 = fig.add_subplot(3, 1, 3)\n",
    "\n",
    "        sb.distplot(df[name]['Log Returns'].fillna(0),\n",
    "                    ax=ax1,\n",
    "                    hist=True,\n",
    "                    bins=int(np.ceil(np.log2(len(df[name])) + 15)),\n",
    "                    label='Datos observados',\n",
    "                    kde=True,\n",
    "                    kde_kws={\"color\":\"k\", \"lw\":2, \"label\":\"KDE\"},\n",
    "                    fit=norm,\n",
    "                    fit_kws = {\"color\":\"r\", \"lw\":3, \"label\":\"Normal Teorica\"})\n",
    "        # TODO: No me esta dando que las frecuencias relativas esten ni cerca de lo esperable\n",
    "        plt.grid(True)\n",
    "        plt.xlabel('Log Returns')\n",
    "        plt.ylabel('Frequency')\n",
    "        #plt.legend(True)\n",
    "        plt.title(f'Histogram for Log returns frequency for {name}')\n",
    "\n",
    "        sb.distplot(df[name]['Abs Returns'].fillna(0),\n",
    "                    ax=ax2,\n",
    "                    hist=True,\n",
    "                    bins=int(np.ceil(np.log2(len(df[name])) + 15)),\n",
    "                    label='Datos observados')\n",
    "                    # SAQUE LO DE ABAJO PQ FLASHIE\n",
    "                    # kde=True,\n",
    "                    # kde_kws={\"color\":\"k\", \"lw\":2, \"label\":\"KDE\"},\n",
    "                    # fit=halfnorm,\n",
    "                    # fit_kws = {\"color\":\"r\", \"lw\":3, \"label\":\"Media Normal Teorica\"})\n",
    "\n",
    "        plt.grid(True)\n",
    "        plt.xlabel('Abs Returns')\n",
    "        plt.ylabel('Frequency')\n",
    "        #plt.legend(True)\n",
    "        plt.title(f'Histogram for Abs Returns frequency for {name}')\n",
    "\n",
    "        sb.distplot(df[name]['Sqr Returns'].fillna(0),\n",
    "                    ax=ax3,\n",
    "                    hist=True,\n",
    "                    bins=int(np.ceil(np.log2(len(df[name])) + 15)),\n",
    "                    label='Datos observados')\n",
    "                    # kde=True,\n",
    "                    # kde_kws={\"color\":\"k\", \"lw\":2, \"label\":\"KDE\"},\n",
    "                    # fit=chi2,\n",
    "                    # fit_kws = {\"color\":\"r\", \"lw\":3, \"label\":\"Chi Cuadrada Teorica\"})\n",
    "\n",
    "        plt.grid(True)\n",
    "        plt.xlabel('Sqr Returns')\n",
    "        plt.ylabel('Frequency')\n",
    "        #plt.legend(True)\n",
    "        plt.title(f'Histogram for Sqr Returns frequency for {name}')\n",
    "\n",
    "        fig.savefig(route_graphs + f'{name}_histogram_returns.png')\n",
    "\n",
    "# histograms(dfs, stocks)\n",
    "def histogram_normal(df, names):\n",
    "    for name in names:\n",
    "        fig = plt.figure(figsize=[13.6, 5.1])\n",
    "        ax1 = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "        sb.distplot(df[name]['Returns'].fillna(0),\n",
    "                    ax=ax1,\n",
    "                    hist=True,\n",
    "                    bins=int(np.ceil(np.log2(len(df[name])) + 15)),\n",
    "                    label='Datos observados',\n",
    "                    fit=norm,\n",
    "                    fit_kws = {\"color\":\"r\", \"lw\":3, \"label\":\"Normal Teorica\"})\n",
    "\n",
    "        plt.grid(True)\n",
    "        plt.xlabel('Log Returns')\n",
    "        plt.ylabel('Frequency')\n",
    "        #plt.legend(True)\n",
    "        plt.title(f'Histogram for simple return frequency for {name}')\n",
    "        fig.savefig(route_graphs + f'{name}_normality_histogram_returns.png')\n",
    "\n",
    "# histogram_normal(dfs, stocks)\n",
    "\n",
    "def normality_test(arr):\n",
    "    arr = arr.fillna(0)\n",
    "    print('Skewness coefficient: ' + str(np.round(scs.skew(arr), 2)))\n",
    "    print('Skewness test p-value: ' + str(1 - np.round(scs.skewtest(arr)[1], 2)))\n",
    "    print('Kurtosis coefficient: ' + str(np.round(scs.kurtosis(arr), 2)))\n",
    "    print('Kurtosis test p-value: ' + str(1 - np.round(scs.kurtosistest(arr)[1], 2)))\n",
    "    print('Normality test p-value: ' + str(1 - np.round(scs.normaltest(arr)[1], 2)))\n",
    "\n",
    "def normality_table(df, names, values):\n",
    "    \"\"\"\n",
    "    :param df: \n",
    "    :param names: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    skew = []\n",
    "    skew_pval = []\n",
    "    kurt = []\n",
    "    kurt_pval = []\n",
    "    norm_pval = []\n",
    "\n",
    "    for name in names:\n",
    "        skew.append(np.round(scs.skew(df[name][values]), 3))\n",
    "        skew_pval.append(np.round(scs.skewtest(df[name][values])[1], 3))\n",
    "        kurt.append(np.round(scs.kurtosis(df[name][values]), 3))\n",
    "        kurt_pval.append(np.round(scs.kurtosistest(df[name][values])[1], 3))\n",
    "        norm_pval.append(np.round(scs.normaltest(df[name][values])[1], 3))\n",
    "\n",
    "    dictionary = {'Skewness':skew, 'Skew p-value':skew_pval, 'Kurtosis':kurt, 'Kurtosis p-value':kurt_pval,\n",
    "                  'Normality test p-value':norm_pval}\n",
    "\n",
    "    table = pd.DataFrame(dictionary)\n",
    "    table.index = names\n",
    "    table.to_csv(route_tables+f'norm_table_{values}.csv')\n",
    "\n",
    "    return table\n",
    "\n",
    "# for rets in return_lists:\n",
    "#     normality_table(dfs, stocks, rets)\n",
    "\n",
    "\n",
    "def describe_and_test_norm(df, names, values):\n",
    "    \"FINALMENTE NO USÃˆ ESTA FUNICON\"\n",
    "    for name in names:\n",
    "        print(values + ' tests for ' + name)\n",
    "        print(df[name][values].describe())\n",
    "        print('')\n",
    "        print(values+' tests for '+name)\n",
    "        normality_test(df[name][values])\n",
    "        print('')\n",
    "        print('-' * 10)\n",
    "\n",
    "    table = normality_table(df, names, values)\n",
    "\n",
    "    return table\n",
    "            \n",
    "\n",
    "# describe_and_test_norm(dfs, stocks, 'Returns')\n",
    "\n",
    "\n",
    "\"\"\n",
    "\n",
    "## para tests de residuales\n",
    "def residuals_test_plot(residual, lags, alpha_graph=0.05,**kwargs):\n",
    "    \"\"\"\n",
    "    TODO: FUNCION SIN USO AUN.\n",
    "    :param residual: The model Residual we want to test\n",
    "    :param lags: the amount of lags we want to run the ACF/PACF on and the lags on the Ljung-Box test\n",
    "    :param alpha_graph: The significance of the graph region\n",
    "    :param name: Name for the graph\n",
    "    :return: the p-value tuple and a saved ACF/PACF graph\n",
    "    \"\"\"\n",
    "    fig = plt.Figure(figsize=[10.2, 13.6])\n",
    "    ax1 = fig.add_subplot(2, 1, 1)\n",
    "    ax2 = fig.add_subplot(2, 1, 2)\n",
    "\n",
    "    plot_acf(residual, lags=lags, zero=False, alpha=alpha_graph, ax=ax1)\n",
    "    plot_pacf(residual, lags=lags, zero=False, alpha=alpha_graph, ax=ax2)\n",
    "    plt.show()\n",
    "\n",
    "    name = kwargs.get('name', 'model')\n",
    "    fig.savefig(f'{name}_ACF_PACF')\n",
    "\n",
    "    test = acorr_ljungbox(residual, lags=lags)\n",
    "\n",
    "    print('The p-values for the residuals are:')\n",
    "    print(test[1])\n"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
