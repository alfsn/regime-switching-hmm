{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Startup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import arch\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.params import get_params\n",
    "from scripts.aux_functions import save_as_pickle\n",
    "\n",
    "params = get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroute = params[\"dataroute\"]\n",
    "resultsroute = params[\"resultsroute\"]\n",
    "dumproute = params[\"dumproute\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = f'finaldf_train_{params[\"tablename\"]}.pickle'\n",
    "filename = os.path.join(dataroute, name)\n",
    "with open(filename, \"rb\") as handle:\n",
    "    df = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GARCHX Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the range of p and q values\n",
    "alpha_values = [1, 2, 3, 4]  # estos son los valores de los lags in mean del AR.\n",
    "p_values = [1, 2, 3]  # Example: p values\n",
    "q_values = [0, 1, 2, 3]  # Example: q values\n",
    "# all models with q=0 are exclusively ARCH (non-GARCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "predict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_aic = {}\n",
    "best_bic = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_best_aic(key, model, previous_best: float, p: int, q: int, dist: str):\n",
    "    \"\"\"\n",
    "    AIC is better when lower.\n",
    "    \"\"\"\n",
    "    if model == None:\n",
    "        pass\n",
    "    else:\n",
    "        if model.aic < previous_best:\n",
    "            best_aic[key] = {\n",
    "                \"model\": model,\n",
    "                \"aic\": model.aic,\n",
    "                \"p\": p,\n",
    "                \"q\": q,\n",
    "                \"dist\": dist,\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_best_bic(key, model, previous_best: float, p: int, q: int, dist: str):\n",
    "    \"\"\"\n",
    "    BIC is better when lower.\n",
    "    \"\"\"\n",
    "    if model == None:\n",
    "        pass\n",
    "    else:\n",
    "        if model.aic < previous_best:\n",
    "            best_bic[key] = {\n",
    "                \"model\": model,\n",
    "                \"bic\": model.bic,\n",
    "                \"p\": p,\n",
    "                \"q\": q,\n",
    "                \"dist\": dist,\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ok: 204\n",
      "nonconverged: 36\n"
     ]
    }
   ],
   "source": [
    "# Estimate ARMA-ARCHX and ARMA-GARCHX models for different p and q values\n",
    "nonconverged_models = 0\n",
    "ok_models = 0\n",
    "\n",
    "for key in params[\"assetlist\"]:\n",
    "    returns = df[f\"{key}_log_rets\"]\n",
    "    exog_rets=df[\"USD_log_rets\"]\n",
    "\n",
    "    models[key] = {}\n",
    "    predict[key] = {}\n",
    "\n",
    "    best_aic[key] = {\"aic\": np.inf}\n",
    "    best_bic[key] = {\"bic\": np.inf}\n",
    "\n",
    "    for p in p_values:\n",
    "        for q in q_values:\n",
    "            for dist in [\"Normal\", \"StudentsT\"]:\n",
    "                model = arch.arch_model(\n",
    "                    returns,\n",
    "                    mean=\"AR\",\n",
    "                    lags=1,\n",
    "                    vol=\"Garch\",\n",
    "                    p=p,\n",
    "                    q=q,\n",
    "                    dist=dist,\n",
    "                    x=exog_rets,\n",
    "                    rescale=False,\n",
    "                )\n",
    "                results = model.fit(\n",
    "                    options={\"maxiter\": 2000}, disp=\"off\", show_warning=False\n",
    "                )\n",
    "\n",
    "                if results.convergence_flag != 0:\n",
    "                    # 0 is converged successfully\n",
    "                    # see https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.fmin_slsqp.html\n",
    "                    results = None\n",
    "                    nonconverged_models += 1\n",
    "                else:\n",
    "                    ok_models += 1\n",
    "\n",
    "                check_best_aic(\n",
    "                    key=key,\n",
    "                    model=results,\n",
    "                    previous_best=best_aic[key][\"aic\"],                    \n",
    "                    p=p,\n",
    "                    q=q,\n",
    "                    dist=dist,\n",
    "                )\n",
    "                check_best_bic(\n",
    "                    key=key,\n",
    "                    model=results,\n",
    "                    previous_best=best_bic[key][\"bic\"],                    \n",
    "                    p=p,\n",
    "                    q=q,\n",
    "                    dist=dist,\n",
    "                )\n",
    "\n",
    "                models[key][(p, q, dist)] = results\n",
    "\n",
    "print()\n",
    "print(f\"ok: {ok_models}\")\n",
    "print(f\"nonconverged: {nonconverged_models}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = f'finaldf_test_{params[\"tablename\"]}.pickle'\n",
    "filename = os.path.join(dataroute, name)\n",
    "with open(filename, \"rb\") as handle:\n",
    "    df_test = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_GARCH_samples_residuals(\n",
    "    model_dict: dict, insample_data: pd.DataFrame, oos_data: pd.DataFrame\n",
    "):\n",
    "    \"\"\"\n",
    "    Esta función come archmodelresults (que vienen del diccionario best_aic y best_bic),\n",
    "    y hace pronósticos rolling (con ventana de 1 año (252 días habiles)),\n",
    "    lo que devuelve samples y residuos.\n",
    "    El método de pronóstico es de simulación\n",
    "\n",
    "    Args:\n",
    "        model_dict (_type_): _description_\n",
    "        pd (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    split_date = insample_data.index[-1]\n",
    "    dates_to_forecast = len(oos_data.index)\n",
    "\n",
    "    full_data = pd.concat([insample_data, oos_data])\n",
    "    del insample_data\n",
    "\n",
    "    # vamos a implementar recursive window forecasting\n",
    "    # https://arch.readthedocs.io/en/latest/univariate/forecasting.html\n",
    "    # https://arch.readthedocs.io/en/latest/univariate/univariate_volatility_forecasting.html#Recursive-Forecast-Generation\n",
    "\n",
    "    index = full_data.index\n",
    "    end_loc = np.where(index >= split_date)[0].min()\n",
    "    # esto es un int del iloc\n",
    "    # preciso usar ints de iloc porque el timedelta se me va a romper con el fin de semana\n",
    "    rolling_window = 252\n",
    "\n",
    "    forecasts = {}\n",
    "\n",
    "    model = arch.arch_model(\n",
    "        y=full_data.iloc[:, 0],\n",
    "        mean=\"AR\",\n",
    "        lags=1,\n",
    "        vol=\"Garch\",\n",
    "        p=model_dict[\"p\"],\n",
    "        q=model_dict[\"q\"],\n",
    "        dist=model_dict[\"dist\"],\n",
    "        x=full_data.iloc[:, 1], \n",
    "        rescale=False,\n",
    "    )\n",
    "\n",
    "    for i in range(0, dates_to_forecast):\n",
    "        date_of_first_forecast = full_data.index[end_loc + i]\n",
    "\n",
    "        res = model.fit(\n",
    "            first_obs=end_loc - rolling_window + i, last_obs=end_loc + i, disp=\"off\"\n",
    "        )\n",
    "\n",
    "        future_x = full_data.iloc[end_loc + i : end_loc + i + 1, 1:2]\n",
    "\n",
    "        forecast = res.forecast(\n",
    "            horizon=1,\n",
    "            start=date_of_first_forecast,\n",
    "            method=\"simulation\",\n",
    "            x=future_x\n",
    "        ).mean.iloc[0]\n",
    "        \n",
    "        forecasts[forecast.name] = forecast\n",
    "\n",
    "    forecasts = pd.DataFrame(forecasts).T\n",
    "    forecasts.columns = pd.DataFrame(full_data.iloc[:, 0]).columns\n",
    "\n",
    "    pct_nan = forecasts.iloc[:, 0].isna().sum() / len(forecasts.index) * 100\n",
    "\n",
    "    if pct_nan > 5:\n",
    "        warnings.warn(f\"{full_data.columns[0]} % na: {pct_nan}\")\n",
    "\n",
    "    forecasts.fillna(method=\"ffill\", inplace=True)\n",
    "\n",
    "    residuals = oos_data - forecasts\n",
    "\n",
    "    return forecasts, residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alfred/github/regime-switching-hmm/thesis/lib/python3.8/site-packages/arch/__future__/_utility.py:11: FutureWarning: \n",
      "The default for reindex is True. After September 2021 this will change to\n",
      "False. Set reindex to True or False to silence this message. Alternatively,\n",
      "you can use the import comment\n",
      "\n",
      "from arch.__future__ import reindexing\n",
      "\n",
      "to globally set reindex to True and silence this warning.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "x is not None but the model does not contain any exogenous variables.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m stock \u001b[38;5;129;01min\u001b[39;00m dictionary\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m      6\u001b[0m     columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstock\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_log_rets\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSD_log_rets\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m----> 7\u001b[0m     forecasts, residuals \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_GARCH_samples_residuals\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdictionary\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstock\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43minsample_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43moos_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     forecasts_dict[criterion][stock]\u001b[38;5;241m=\u001b[39mforecasts\n\u001b[1;32m     14\u001b[0m     residuals_dict[criterion][stock]\u001b[38;5;241m=\u001b[39mresiduals     \n",
      "Cell \u001b[0;32mIn[13], line 56\u001b[0m, in \u001b[0;36mgenerate_GARCH_samples_residuals\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m     res \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m     51\u001b[0m         first_obs\u001b[38;5;241m=\u001b[39mend_loc \u001b[38;5;241m-\u001b[39m rolling_window \u001b[38;5;241m+\u001b[39m i, last_obs\u001b[38;5;241m=\u001b[39mend_loc \u001b[38;5;241m+\u001b[39m i, disp\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     52\u001b[0m     )\n\u001b[1;32m     54\u001b[0m     future_x \u001b[38;5;241m=\u001b[39m full_data\u001b[38;5;241m.\u001b[39miloc[end_loc \u001b[38;5;241m+\u001b[39m i : end_loc \u001b[38;5;241m+\u001b[39m i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m---> 56\u001b[0m     forecast \u001b[38;5;241m=\u001b[39m \u001b[43mres\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforecast\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhorizon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_of_first_forecast\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msimulation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfuture_x\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     63\u001b[0m     forecasts[forecast\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m forecast\n\u001b[1;32m     65\u001b[0m forecasts \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(forecasts)\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[0;32m~/github/regime-switching-hmm/thesis/lib/python3.8/site-packages/arch/univariate/base.py:1519\u001b[0m, in \u001b[0;36mARCHModelFixedResult.forecast\u001b[0;34m(self, params, horizon, start, align, method, simulations, rng, random_state, reindex, x)\u001b[0m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(horizon, (\u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39minteger)) \u001b[38;5;129;01mor\u001b[39;00m horizon \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1518\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhorizon must be an integer >= 1.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1519\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforecast\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhorizon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1523\u001b[0m \u001b[43m    \u001b[49m\u001b[43malign\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1525\u001b[0m \u001b[43m    \u001b[49m\u001b[43msimulations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1527\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1528\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1530\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/github/regime-switching-hmm/thesis/lib/python3.8/site-packages/arch/univariate/mean.py:1002\u001b[0m, in \u001b[0;36mHARX.forecast\u001b[0;34m(self, params, horizon, start, align, method, simulations, rng, random_state, reindex, x)\u001b[0m\n\u001b[1;32m   1000\u001b[0m constant \u001b[38;5;241m=\u001b[39m arp[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstant \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m   1001\u001b[0m dynp \u001b[38;5;241m=\u001b[39m arp[\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstant) :]\n\u001b[0;32m-> 1002\u001b[0m expected_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reformat_forecast_x\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhorizon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1003\u001b[0m mean_fcast \u001b[38;5;241m=\u001b[39m _ar_forecast(\n\u001b[1;32m   1004\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_y, horizon, start_index, constant, dynp, expected_x, exog_p\n\u001b[1;32m   1005\u001b[0m )\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;66;03m# Compute total variance forecasts, which depend on model\u001b[39;00m\n",
      "File \u001b[0;32m~/github/regime-switching-hmm/thesis/lib/python3.8/site-packages/arch/univariate/mean.py:859\u001b[0m, in \u001b[0;36mHARX._reformat_forecast_x\u001b[0;34m(self, x, horizon, start)\u001b[0m\n\u001b[1;32m    853\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    854\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx is None but the model contains exogenous variables. You must \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    855\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprovide expected values to use for the exogenous variables to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    856\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstruct forecasts.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    857\u001b[0m         )\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 859\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    860\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx is not None but the model does not contain any exogenous \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    861\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvariables.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    862\u001b[0m     )\n\u001b[1;32m    863\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    864\u001b[0m nx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: x is not None but the model does not contain any exogenous variables."
     ]
    }
   ],
   "source": [
    "forecasts_dict={\"aic\":{}, \"bic\":{}}\n",
    "residuals_dict={\"aic\":{}, \"bic\":{}}\n",
    "\n",
    "for criterion, dictionary in zip([\"aic\", \"bic\"], [best_aic, best_bic]):\n",
    "    for stock in dictionary.keys():\n",
    "        columns=[f\"{stock}_log_rets\", \"USD_log_rets\"]\n",
    "        forecasts, residuals = generate_GARCH_samples_residuals(\n",
    "            model_dict=dictionary[stock],\n",
    "            insample_data=pd.DataFrame(df[columns]),\n",
    "            oos_data=pd.DataFrame(df_test[columns])\n",
    "            )\n",
    "\n",
    "        forecasts_dict[criterion][stock]=forecasts\n",
    "        residuals_dict[criterion][stock]=residuals     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for criterion, bestmodels in zip([\"aic\", \"bic\"], [best_aic, best_bic]):\n",
    "    save_as_pickle(\n",
    "        data=forecasts_dict[criterion],\n",
    "        resultsroute=params[\"resultsroute\"],\n",
    "        model_type=\"GARCH-X\",\n",
    "        tablename=params[\"tablename\"],\n",
    "        criterion=criterion,\n",
    "        type_save=\"forecasts\",\n",
    "    )\n",
    "\n",
    "    save_as_pickle(\n",
    "        data=residuals_dict[criterion],\n",
    "        resultsroute=params[\"resultsroute\"],\n",
    "        model_type=\"GARCH-X\",\n",
    "        tablename=params[\"tablename\"],\n",
    "        criterion=criterion,\n",
    "        type_save=\"residuals\"\n",
    "    )\n",
    "\n",
    "    save_as_pickle(\n",
    "        data=bestmodels,\n",
    "        resultsroute=params[\"resultsroute\"],\n",
    "        model_type=\"GARCH-X\",\n",
    "        tablename=params[\"tablename\"],\n",
    "        criterion=criterion,\n",
    "        type_save=\"models\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
